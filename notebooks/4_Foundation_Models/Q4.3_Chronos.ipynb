{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2405308b-b436-407c-8e71-c70884fc43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from modules import * \n",
    "\n",
    "# override all pandas display limits\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4aa398f-7502-45e1-b2fd-c25a577c80ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a-filled.parquet -> set_a_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b.parquet -> set_b\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a.parquet -> set_a\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c-filled.parquet -> set_c_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c.parquet -> set_c\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b-filled.parquet -> set_b_filled\n"
     ]
    }
   ],
   "source": [
    "# load parquet files\n",
    "data_path = Path(\"../../data\")\n",
    "notebooks_path = Path(os.getcwd())\n",
    "data_dir = {}\n",
    "\n",
    "##unsafe\n",
    "# for file_path in list((notebooks_path / data_path).glob(\"*.parquet\")):\n",
    "#     print(f\"Reading {file_path}\")\n",
    "#     # retrieve the name of the file without the extension for all OS\n",
    "#     data = pd.read_parquet(file_path)\n",
    "#     # if \"Time\" in df.columns:\n",
    "#     #     df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "#     data_dir[str(file_path).replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0].replace(\"-\", \"_\")] = data\n",
    "\n",
    "for file_path in (notebooks_path / data_path).glob(\"set*.parquet\"):\n",
    "    var_name = file_path.stem.replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_parquet(file_path)\n",
    "    print(f\"Reading {file_path} -> {var_name}\")\n",
    "\n",
    "\n",
    "ID_vars = [\"PatientID\", \"Time\", \"RecordID\"] # TODO \n",
    "# stationary variables\n",
    "stationary_vars = [\"Age\", \"Gender\", \"Height\"] #, \"ICUType\"]\n",
    "# dynamic variables\n",
    "dynamic_vars = set_a.columns.difference(stationary_vars + ID_vars).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5ce5cc-b1d4-43bd-bd0a-93c2124d4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parquet_for_lstm(key, scaler=None, fit_scaler=False):\n",
    "    labelname = 'In-hospital_death'\n",
    "    df = globals()[f\"set_{key}_filled\"].copy()\n",
    "\n",
    "    # Sort and fill NaNs\n",
    "    df = df.sort_values([\"RecordID\", \"Time\"])\n",
    "    df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "    # raise NotImplementedError(\"Encode cathegories\")\n",
    "\n",
    "    # --- Fit scaler on all feature data if requested ---\n",
    "    if fit_scaler or scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[feature_cols])\n",
    "\n",
    "    # --- Apply scaling ---\n",
    "    df[feature_cols] = scaler.transform(df[feature_cols])\n",
    "\n",
    "    # Group by patient\n",
    "    X = []\n",
    "    y = []\n",
    "    for pid, group in df.groupby(\"RecordID\"):\n",
    "        group = group.sort_values(\"Time\")\n",
    "        X.append(group[feature_cols].values)\n",
    "        y.append(group[labelname].iloc[0])\n",
    "\n",
    "    X_tensor = torch.tensor(np.stack(X)).float()  # (n_patients, seq_len, n_features)\n",
    "    y_tensor = torch.tensor(y).float()            # (n_patients,)\n",
    "\n",
    "    return X_tensor, y_tensor, scaler  # return scaler for reuse on val/test\n",
    "\n",
    "feature_cols = dynamic_vars + stationary_vars\n",
    "X_train, y_train, fitted_scaler = preprocess_parquet_for_lstm(\"a\", fit_scaler = True)\n",
    "# len(preprocess_parquet_for_lstm(\"b\", scaler = fitted_scaler))\n",
    "X_val, y_val , _    = preprocess_parquet_for_lstm(\"b\", scaler = fitted_scaler)\n",
    "X_test, y_test , _  = preprocess_parquet_for_lstm(\"c\", scaler = fitted_scaler)\n",
    "\n",
    "# extract dimensions\n",
    "num_patients, sequence_length, num_features  = X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ce486f-cb67-4fca-a6fc-8ce42797b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load the pretrained Chronos model\n",
    "model_id = \"amazon/chronos-t5-small\"  # Example model; choose the one that fits your needs\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
    "    device_map=device,  # use \"cpu\" for CPU inference\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "# Manually move tokenizer boundaries to match model device\n",
    "pipeline.tokenizer.boundaries = pipeline.tokenizer.boundaries.to(pipeline.model.device)\n",
    "\n",
    "# Fix Chronos tokenizer device mismatch when appending EOS token\n",
    "def patched_append_eos_token(self, token_ids, attention_mask):\n",
    "    device = token_ids.device\n",
    "    batch_size = token_ids.shape[0]\n",
    "    eos_tokens = torch.full((batch_size, 1), fill_value=self.config.eos_token_id, device=device)\n",
    "    eos_mask = torch.full((batch_size, 1), fill_value=True, device=device)\n",
    "    token_ids = torch.concat((token_ids, eos_tokens), dim=1)\n",
    "    attention_mask = torch.concat((attention_mask, eos_mask), dim=1)\n",
    "    return token_ids, attention_mask\n",
    "\n",
    "# Patch the method\n",
    "pipeline.tokenizer._append_eos_token = patched_append_eos_token.__get__(pipeline.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dcd1cd-b6f6-4213-b00e-1cf960402a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train_embeddings, X_train_embeddings_list = \u001b[43mget_chronos_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m X_val_embeddings, X_val_embeddings = get_chronos_embeddings(X_val)\n\u001b[32m      3\u001b[39m X_test_embeddings, X_test_embeddings = get_chronos_embeddings(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/modules.py:197\u001b[39m, in \u001b[36mget_chronos_embeddings\u001b[39m\u001b[34m(X_tensor)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_chronos_embeddings\u001b[39m(X_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     X_tensor = X_tensor.to(\u001b[43mdevice\u001b[49m)\n\u001b[32m    198\u001b[39m     embedding_sum = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    199\u001b[39m     embedding_list = []\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_embeddings, X_train_embeddings_list = get_chronos_embeddings(X_train)\n",
    "X_val_embeddings, X_val_embeddings = get_chronos_embeddings(X_val)\n",
    "X_test_embeddings, X_test_embeddings = get_chronos_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cf6be9-1a85-4719-8288-d2cf65d825f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2003, dtype=torch.float16)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18a9f99-28f8-458a-a386-29ec972777d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 50, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
