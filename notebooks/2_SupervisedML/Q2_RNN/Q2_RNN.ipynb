{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "## Lib and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# override all pandas display limits\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\paesc\\OneDrive\\docs\\projects\\ICU-TimeSeries-Mortality-Prediction\\notebooks\\2_SupervisedML\\Q2_RNN\\..\\..\\..\\data\\Outcomes-a.parquet\n",
      "Reading c:\\Users\\paesc\\OneDrive\\docs\\projects\\ICU-TimeSeries-Mortality-Prediction\\notebooks\\2_SupervisedML\\Q2_RNN\\..\\..\\..\\data\\Outcomes-b.parquet\n",
      "Reading c:\\Users\\paesc\\OneDrive\\docs\\projects\\ICU-TimeSeries-Mortality-Prediction\\notebooks\\2_SupervisedML\\Q2_RNN\\..\\..\\..\\data\\Outcomes-c.parquet\n",
      "Reading c:\\Users\\paesc\\OneDrive\\docs\\projects\\ICU-TimeSeries-Mortality-Prediction\\notebooks\\2_SupervisedML\\Q2_RNN\\..\\..\\..\\data\\set-a.parquet\n",
      "Reading c:\\Users\\paesc\\OneDrive\\docs\\projects\\ICU-TimeSeries-Mortality-Prediction\\notebooks\\2_SupervisedML\\Q2_RNN\\..\\..\\..\\data\\set-b.parquet\n",
      "Reading c:\\Users\\paesc\\OneDrive\\docs\\projects\\ICU-TimeSeries-Mortality-Prediction\\notebooks\\2_SupervisedML\\Q2_RNN\\..\\..\\..\\data\\set-c.parquet\n"
     ]
    }
   ],
   "source": [
    "# load parquet files\n",
    "data_path = Path(\"../../../data\")\n",
    "notebooks_path = Path(os.getcwd())\n",
    "data_dir = {}\n",
    "\n",
    "##unsafe\n",
    "# for file_path in list((notebooks_path / data_path).glob(\"*.parquet\")):\n",
    "#     print(f\"Reading {file_path}\")\n",
    "#     # retrieve the name of the file without the extension for all OS\n",
    "#     data = pd.read_parquet(file_path)\n",
    "#     # if \"Time\" in df.columns:\n",
    "#     #     df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "#     data_dir[str(file_path).replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0].replace(\"-\", \"_\")] = data\n",
    "\n",
    "for file_path in (notebooks_path / data_path).glob(\"*.parquet\"):\n",
    "    print(f\"Reading {file_path}\")\n",
    "    var_name = file_path.stem.replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_parquet(file_path)\n",
    "\n",
    "\n",
    "ID_vars = [\"PatientID\", \"Time\", \"RecordID\"]\n",
    "# stationary variables\n",
    "stationary_vars = [\"Age\", \"Gender\", \"Height\", \"ICUType\"]\n",
    "# dynamic variables\n",
    "dynamic_vars = set_a.columns.difference(stationary_vars + ID_vars).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_cols,\n",
    "        batch_size=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def preprocess_parquet_for_lstm(self, key):\n",
    "        X = []\n",
    "        y = globals()[f\"Outcomes_{key}\"][\"In-hospital_death\"].values\n",
    "\n",
    "        for pid, data in globals()[f\"set_{key}\"].groupby(\"PatientID\"):\n",
    "            data = data.sort_values(\"Time\")\n",
    "            # TODO: Replace with real imputation\n",
    "            data.fillna(0, inplace=True)\n",
    "            X.append(data[self.feature_cols].values)\n",
    "\n",
    "        return torch.tensor(np.stack(X)).float(), torch.tensor(y).float()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.X_train, self.y_train = self.preprocess_parquet_for_lstm(\"a\")\n",
    "        self.X_val, self.y_val     = self.preprocess_parquet_for_lstm(\"b\")\n",
    "        self.X_test, self.y_test   = self.preprocess_parquet_for_lstm(\"c\")\n",
    "\n",
    "        self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        self.val_dataset   = TensorDataset(self.X_val, self.y_val)\n",
    "        self.test_dataset  = TensorDataset(self.X_test, self.y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | lstm       | LSTM              | 60.7 K | train\n",
      "1 | classifier | Linear            | 65     | train\n",
      "2 | loss_fn    | BCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "60.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.7 K    Total params\n",
      "0.243     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cea2f66b2c4b25a070585c07b1d3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paesc\\anaconda3\\envs\\py311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\paesc\\anaconda3\\envs\\py311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae0fcd4b060440297bc2cc319187119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6a908a5a9b4ad0ab1888750da753f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.403\n",
      "Epoch 0, global step 63: 'val_loss' reached 0.40297 (best 0.40297), saving model to 'c:\\\\Users\\\\paesc\\\\OneDrive\\\\docs\\\\projects\\\\ICU-TimeSeries-Mortality-Prediction\\\\notebooks\\\\2_SupervisedML\\\\Q2_RNN\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02f86b81e7b4a86955ba83d29040eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paesc\\anaconda3\\envs\\py311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "c:\\Users\\paesc\\anaconda3\\envs\\py311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbacd517b6ae43bebef0a1b3df91bc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8537499904632568\n",
      "        test_loss            0.410361647605896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.410361647605896, 'test_acc': 0.8537499904632568}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run input through the LSTM\n",
    "        _, (hidden_state, _) = self.lstm(x)  # lstm_output, (hidden_state, cell_state)\n",
    "\n",
    "        # Take the last layer's hidden state (for stacked LSTM)\n",
    "        last_hidden = hidden_state[-1]  # shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Pass through the classification head\n",
    "        logits = self.classifier(last_hidden)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        acc = (preds.int() == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        acc = (preds.int() == y).float().mean()\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "\n",
    "# Callbacks for trainer\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=True, mode='min')\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', mode='min', save_top_k=1, verbose=True, filename='best-checkpoint')\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Example Training Loop\n",
    "# -------------------------------\n",
    "# Ensure you have torch tensors: X_train, y_train, X_val, y_val, X_test, y_test\n",
    "# And shape: [n_samples, seq_len, n_features] for X_* and [n_samples] for y_*\n",
    "\n",
    "# Instantiate\n",
    "feature_cols = dynamic_vars + stationary_vars\n",
    "datamodule = TimeSeriesDataModule(feature_cols=feature_cols, batch_size=64)\n",
    "model = LSTMClassifier(input_size=len(feature_cols), hidden_size=64, num_layers=2)\n",
    "\n",
    "\n",
    "\n",
    "# # Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[early_stop_callback, lr_monitor, checkpoint_callback],\n",
    "    log_every_n_steps=10,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\"\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "trainer.test(model, datamodule=datamodule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
