{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ac64eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.6.1\n",
      "aiohttp==3.11.16\n",
      "aiosignal==1.3.2\n",
      "anyio==3.6.2\n",
      "appnope @ file:///Users/runner/miniforge3/conda-bld/appnope_1635819658021/work\n",
      "argon2-cffi @ file:///Users/runner/miniforge3/conda-bld/argon2-cffi_1636021583814/work\n",
      "async-generator==1.10\n",
      "async-timeout==5.0.1\n",
      "attrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1620387926260/work\n",
      "backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n",
      "backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n",
      "beautifulsoup4==4.11.1\n",
      "bleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1629908509068/work\n",
      "brotlipy==0.7.0\n",
      "certifi==2022.12.7\n",
      "cffi @ file:///Users/runner/miniforge3/conda-bld/cffi_1631636293358/work\n",
      "chardet @ file:///Users/runner/miniforge3/conda-bld/chardet_1610093454858/work\n",
      "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1626371162869/work\n",
      "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1602866480661/work\n",
      "conda==23.1.0\n",
      "conda-pack==0.6.0\n",
      "conda-package-handling @ file:///Users/runner/miniforge3/conda-bld/conda-package-handling_1618231726924/work\n",
      "cryptography @ file:///Users/runner/miniforge3/conda-bld/cryptography_1633983374178/work\n",
      "cycler==0.11.0\n",
      "debugpy @ file:///Users/runner/miniforge3/conda-bld/debugpy_1636043380823/work\n",
      "decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1631346842025/work\n",
      "defusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\n",
      "entrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1605121927639/work/dist/entrypoints-0.3-py2.py3-none-any.whl\n",
      "fastjsonschema==2.16.2\n",
      "fastq==2.0.1\n",
      "filelock==3.18.0\n",
      "fonttools==4.28.3\n",
      "frozenlist==1.5.0\n",
      "fsspec==2025.3.2\n",
      "gillespy2==1.7.1\n",
      "idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1609836280497/work\n",
      "importlib-metadata @ file:///Users/runner/miniforge3/conda-bld/importlib-metadata_1636431822059/work\n",
      "importlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1635615662634/work\n",
      "ipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1638246197849/work/dist/ipykernel-6.5.1-py3-none-any.whl\n",
      "ipython @ file:///Users/runner/miniforge3/conda-bld/ipython_1637978921616/work\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1631590360471/work\n",
      "jedi @ file:///Users/runner/miniforge3/conda-bld/jedi_1637175418640/work\n",
      "Jinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1636510082894/work\n",
      "joblib==1.1.0\n",
      "jsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema_1636165360877/work\n",
      "jupyter @ file:///Users/runner/miniforge3/conda-bld/jupyter_1637233473259/work\n",
      "jupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1637611911738/work\n",
      "jupyter-console @ file:///home/conda/feedstock_root/build_artifacts/jupyter_console_1616560109969/work\n",
      "jupyter-core @ file:///Users/runner/miniforge3/conda-bld/jupyter_core_1636814382648/work\n",
      "jupyter-server==1.23.2\n",
      "jupyterlab-pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1601375948261/work\n",
      "jupyterlab-widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1631590465624/work\n",
      "kiwisolver==1.3.2\n",
      "lightning-utilities==0.14.2\n",
      "lxml==4.9.1\n",
      "MarkupSafe @ file:///Users/runner/miniforge3/conda-bld/markupsafe_1635833679368/work\n",
      "matplotlib==3.5.1\n",
      "matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\n",
      "miniFasta==3.0.2\n",
      "mistune @ file:///Users/runner/miniforge3/conda-bld/mistune_1635844817800/work\n",
      "mpmath==1.3.0\n",
      "multidict==6.3.1\n",
      "nbclassic==0.4.8\n",
      "nbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1637327213451/work\n",
      "nbconvert==6.5.4\n",
      "nbformat==5.7.0\n",
      "nest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1617163391303/work\n",
      "networkx==3.2.1\n",
      "notebook==6.5.2\n",
      "notebook_shim==0.2.2\n",
      "numpy==1.21.4\n",
      "packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\n",
      "pafpy @ file:///opt/conda/conda-bld/pafpy_1612152872599/work\n",
      "pandas==1.4.2\n",
      "pandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\n",
      "parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1617148930513/work\n",
      "pathlib==1.0.1\n",
      "pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\n",
      "pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n",
      "Pillow==8.4.0\n",
      "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1667232663820/work\n",
      "prometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1635538335951/work\n",
      "prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1636045889479/work\n",
      "propcache==0.3.1\n",
      "ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "pyarrow==19.0.1\n",
      "pycosat @ file:///Users/runner/miniforge3/conda-bld/pycosat_1624996792650/work\n",
      "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\n",
      "Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1629119114968/work\n",
      "pyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1633192417276/work\n",
      "pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1636757021002/work\n",
      "pyrsistent @ file:///Users/runner/miniforge3/conda-bld/pyrsistent_1636052709890/work\n",
      "PySide6==6.4.2\n",
      "PySide6-Addons==6.4.2\n",
      "PySide6-Essentials==6.4.2\n",
      "PySocks @ file:///Users/runner/miniforge3/conda-bld/pysocks_1610291460269/work\n",
      "python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n",
      "pytorch-lightning==2.5.1\n",
      "pytz==2022.1\n",
      "PyYAML==6.0.2\n",
      "pyzmq @ file:///Users/runner/miniforge3/conda-bld/pyzmq_1635877593130/work\n",
      "qtconsole==5.6.1\n",
      "QtPy==2.4.3\n",
      "requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1626393743643/work\n",
      "ruamel-yaml-conda @ file:///Users/runner/miniforge3/conda-bld/ruamel_yaml_1624999868738/work\n",
      "ruamel.yaml @ file:///Users/runner/miniforge3/conda-bld/ruamel.yaml_1666827345171/work\n",
      "ruamel.yaml.clib @ file:///Users/runner/miniforge3/conda-bld/ruamel.yaml.clib_1670412837369/work\n",
      "scikit-learn==1.0.2\n",
      "scipy==1.8.0\n",
      "seaborn==0.13.2\n",
      "Send2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1628511208346/work\n",
      "shiboken6==6.4.2\n",
      "six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n",
      "sniffio==1.3.0\n",
      "soupsieve==2.3.2.post1\n",
      "sympy==1.13.1\n",
      "tenacity==8.1.0\n",
      "terminado @ file:///Users/runner/miniforge3/conda-bld/terminado_1636052406972/work\n",
      "testpath @ file:///home/conda/feedstock_root/build_artifacts/testpath_1621261527237/work\n",
      "threadpoolctl==3.1.0\n",
      "tinycss2==1.2.1\n",
      "toolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1657485559105/work\n",
      "torch==2.1.2\n",
      "torch-cluster==1.6.0\n",
      "torch-geometric==2.0.4\n",
      "torch-scatter==2.0.9\n",
      "torch-sparse==0.6.13\n",
      "torch-spline-conv==1.2.1\n",
      "torchmetrics==1.7.0\n",
      "torchtext==0.10.0\n",
      "tornado @ file:///Users/runner/miniforge3/conda-bld/tornado_1635819711289/work\n",
      "tqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1632160078689/work\n",
      "traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1635260543454/work\n",
      "typing_extensions==4.6.3\n",
      "urllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1632350318291/work\n",
      "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "widgetsnbextension @ file:///Users/runner/miniforge3/conda-bld/widgetsnbextension_1637174654032/work\n",
      "xgboost==2.1.4\n",
      "yarl==1.18.3\n",
      "zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1633302054558/work\n",
      "Requirement already satisfied: typing_extensions==4.6.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (4.6.3)\n",
      "Requirement already satisfied: pytorch-lightning==2.5.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: torch>=2.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (4.62.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (2025.3.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (1.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (4.6.3)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lightning==2.5.1) (0.14.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (3.11.16)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning==2.5.1) (58.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from packaging>=20.0->pytorch-lightning==2.5.1) (3.0.6)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (3.18.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (3.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>1.20.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torchmetrics>=0.7.0->pytorch-lightning==2.5.1) (1.21.4)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (21.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (6.3.1)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (1.18.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning==2.5.1) (2.0.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from sympy->torch>=2.1.0->pytorch-lightning==2.5.1) (1.3.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze\n",
    "!pip install typing_extensions==4.6.3 \n",
    "!pip install pytorch-lightning==2.5.1\n",
    "PL_FAULT_TOLERANT_TRAINING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942d78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data\")\n",
    "set_a_filled = pd.read_parquet(\"set-a-filled.parquet\")\n",
    "set_b_filled = pd.read_parquet(\"set-b-filled.parquet\")\n",
    "set_c_filled = pd.read_parquet(\"set-c-filled.parquet\")\n",
    "\n",
    "\n",
    "class LSTMAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.encoder = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size=hidden_size, hidden_size=input_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden_state, _) = self.encoder(x)\n",
    "        embedding = hidden_state[-1].unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        reconstructed, _ = self.decoder(embedding)\n",
    "        return reconstructed\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch  # ignore labels\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_fn(x_hat, x)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_fn(x_hat, x)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7396606",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, feature_cols, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def preprocess_parquet_for_lstm(self, key, scaler=None, fit_scaler=False):\n",
    "        labelname = 'In-hospital_death'\n",
    "        df = globals()[f\"set_{key}_filled\"].copy()\n",
    "        df = df.sort_values([\"RecordID\", \"Time\"])\n",
    "        df[self.feature_cols] = df[self.feature_cols].fillna(0)\n",
    "\n",
    "        # Fit/transform\n",
    "        if fit_scaler or scaler is None:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[self.feature_cols])\n",
    "        df[self.feature_cols] = scaler.transform(df[self.feature_cols])\n",
    "\n",
    "        # Group by patient\n",
    "        X, y = [], []\n",
    "        for pid, group in df.groupby(\"RecordID\"):\n",
    "            group = group.sort_values(\"Time\")\n",
    "            X.append(group[self.feature_cols].values)\n",
    "            y.append(group[labelname].iloc[0])\n",
    "\n",
    "        X_tensor = torch.tensor(np.stack(X)).float()\n",
    "        y_tensor = torch.tensor(y).float()\n",
    "        return X_tensor, y_tensor, scaler\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.X_train, self.y_train, scaler = self.preprocess_parquet_for_lstm(\"a\", fit_scaler=True)\n",
    "        self.X_val, self.y_val, _ = self.preprocess_parquet_for_lstm(\"b\", scaler=scaler)\n",
    "        self.X_test, self.y_test, _ = self.preprocess_parquet_for_lstm(\"c\", scaler=scaler)\n",
    "\n",
    "        self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        self.val_dataset = TensorDataset(self.X_val, self.y_val)\n",
    "        self.test_dataset = TensorDataset(self.X_test, self.y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30af702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_cols = set_a_filled.columns.difference([\"PatientID\", \"Time\", \"RecordID\", \"In-hospital_death\"]).tolist()\n",
    "datamodule = TimeSeriesDataModule(feature_cols)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5b593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | LSTM    | 27.4 K | train\n",
      "1 | decoder | LSTM    | 17.5 K | train\n",
      "2 | loss_fn | MSELoss | 0      | train\n",
      "--------------------------------------------\n",
      "44.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.9 K    Total params\n",
      "0.180     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ef7d1e2676483badfc96a7db52651c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "def train_autoencoder(model, datamodule, max_epochs=20):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        log_every_n_steps=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        default_root_dir=\"autoencoder_logs\"\n",
    "    )\n",
    "    trainer.fit(model, datamodule)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_size = len(datamodule.feature_cols)\n",
    "autoencoder = LSTMAutoencoder(input_size=input_size)\n",
    "autoencoder = train_autoencoder(autoencoder, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4b2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, dataloader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(model.device)\n",
    "            _, (hidden_state, _) = model.encoder(x)\n",
    "            z = hidden_state[-1]  # shape: (batch, hidden_size)\n",
    "            embeddings.append(z.cpu().numpy())\n",
    "            labels.append(y.cpu().numpy())\n",
    "    return np.vstack(embeddings), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e66166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_linear_probe(embeddings, labels):\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(embeddings, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ff6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def evaluate_probe(clf, embeddings, labels):\n",
    "    probs = clf.predict_proba(embeddings)[:, 1]\n",
    "    auroc = roc_auc_score(labels, probs)\n",
    "    auprc = average_precision_score(labels, probs)\n",
    "    print(f\"ðŸ“Š Linear Probe Performance:\\n - AuROC: {auroc:.4f}\\n - AuPRC: {auprc:.4f}\")\n",
    "    return auroc, auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2171be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Linear Probe Performance:\n",
      " - AuROC: 0.8480\n",
      " - AuPRC: 0.4996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8479768742726285, 0.49961778330298107)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get embeddings from the frozen encoder\n",
    "X_train_embed, y_train = extract_embeddings(autoencoder, datamodule.train_dataloader())\n",
    "X_test_embed, y_test = extract_embeddings(autoencoder, datamodule.test_dataloader())\n",
    "\n",
    "# Train and evaluate linear probe\n",
    "probe = train_linear_probe(X_train_embed, y_train)\n",
    "evaluate_probe(probe, X_test_embed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8283d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Linear Probe Evaluation (Frozen LSTM Autoencoder Embeddings):\n",
      " - Precision : 0.6244\n",
      " - Recall    : 0.2359\n",
      " - F1 Score  : 0.3424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Use predicted probabilities from logistic regression\n",
    "probs = probe.predict_proba(X_test_embed)[:, 1]\n",
    "\n",
    "# Binary predictions with default threshold 0.5\n",
    "y_pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"ðŸ“Š Linear Probe Evaluation (Frozen LSTM Autoencoder Embeddings):\")\n",
    "print(f\" - Precision : {precision:.4f}\")\n",
    "print(f\" - Recall    : {recall:.4f}\")\n",
    "print(f\" - F1 Score  : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43360f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
