{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96acc0fc-0275-4348-85e7-2c98524217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import (LogisticRegression, LinearRegression)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from ollama import chat\n",
    "from ollama import embeddings\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from modules import *\n",
    "\n",
    "# override all pandas display limits\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6205bbfd-552d-4b6c-9472-3924bb508654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a-filled.parquet -> set_a_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b.parquet -> set_b\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a.parquet -> set_a\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c-filled.parquet -> set_c_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c.parquet -> set_c\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b-filled.parquet -> set_b_filled\n"
     ]
    }
   ],
   "source": [
    "# load parquet files\n",
    "data_path = Path(\"../../data\")\n",
    "notebooks_path = Path(os.getcwd())\n",
    "data_dir = {}\n",
    "\n",
    "##unsafe\n",
    "# for file_path in list((notebooks_path / data_path).glob(\"*.parquet\")):\n",
    "#     print(f\"Reading {file_path}\")\n",
    "#     # retrieve the name of the file without the extension for all OS\n",
    "#     data = pd.read_parquet(file_path)\n",
    "#     # if \"Time\" in df.columns:\n",
    "#     #     df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "#     data_dir[str(file_path).replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0].replace(\"-\", \"_\")] = data\n",
    "\n",
    "for file_path in (notebooks_path / data_path).glob(\"set*.parquet\"):\n",
    "    var_name = file_path.stem.replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_parquet(file_path)\n",
    "    print(f\"Reading {file_path} -> {var_name}\")\n",
    "\n",
    "\n",
    "ID_vars = [\"PatientID\", \"Time\", \"RecordID\"]\n",
    "# stationary variables\n",
    "stationary_vars = [\"Age\", \"Gender\", \"Height\"] #, \"ICUType\"]\n",
    "# dynamic variables\n",
    "dynamic_vars = set_a.columns.difference(stationary_vars + ID_vars).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef950db1-2fa2-4cfb-b4eb-686597051882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in [\"a\", \"b\", \"c\"]:\n",
    "#     print(f\"Extracting set_{key}\") \n",
    "#     df = extract_features(globals()[f\"set_{key}_filled\"])\n",
    "#     df.to_csv(notebooks_path / data_path / Path(f\"features_{key}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072b4f46-74fe-4e5b-9f67-9e3ee46a75fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/features_a.csv -> features_a\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/features_c.csv -> features_c\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/features_b.csv -> features_b\n"
     ]
    }
   ],
   "source": [
    "for file_path in (notebooks_path / data_path).glob(\"features*.csv\"):\n",
    "    var_name = file_path.stem.replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_csv(file_path)\n",
    "    print(f\"Reading {file_path} -> {var_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d91b5b-4bef-453f-b6d0-064bff091cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest to check feature importance for classification\n",
    "def split_labels_and_features(df):\n",
    "    exclude = [\"In-hospital_death\", \"RecordID\", \"Unnamed\", \"ICUType\"]\n",
    "    labels = df['In-hospital_death_mean']\n",
    "    features = df.loc[:, ~df.columns.str.contains(\"|\".join(exclude))].copy()\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "# ## top k features\n",
    "# top_k_features = 20\n",
    "\n",
    "# X_train, y_train = split_labels_and_features(features_a)\n",
    "\n",
    "# # Assuming you've already trained your Random Forest\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# # Extract importances\n",
    "# importances = rf.feature_importances_\n",
    "\n",
    "# # Create a sorted DataFrame\n",
    "# feature_names = X_train.columns if isinstance(X_train, pd.DataFrame) else [f\"f{i}\" for i in range(X_train.shape[1])]\n",
    "# importance_df = pd.DataFrame({\n",
    "#     \"Feature\": feature_names,\n",
    "#     \"Importance\": importances\n",
    "# }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# # Print top features\n",
    "# print(importance_df.head(top_k_features))\n",
    "\n",
    "# # Optional: plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(importance_df[\"Feature\"][:top_k_features][::-1], importance_df[\"Importance\"][:20][::-1])\n",
    "# plt.xlabel(\"Importance\")\n",
    "# plt.title(\"Top 20 Feature Importances\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb63b10b-2690-4b1b-9eec-eb072fa50831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df is your test set DataFrame with top features + labels\n",
    "# !ollama serve\n",
    "# !ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86370ec0-4743-4a7f-8d81-91b603b7ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVP\n",
    "# max_cases = 1\n",
    "# scoring_bool = True\n",
    "\n",
    "# prompt, test_cases, outcomes = build_few_shot_prompt(features_a, label_col = \"In-hospital_death_mean\", scoring = scoring_bool)\n",
    "\n",
    "\n",
    "# for i, test_case in enumerate(test_cases[:max_cases]):\n",
    "#     print(f\"\\n--- Test Case {i+1} ---\")\n",
    "#     prediction = query_llm(prompt, test_case).lower()\n",
    "#     print(f\"Prediction: {prediction}\")\n",
    "#     print(f\"Truth: {outcomes[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0a9199-2aaa-4920-8864-df7df0fed88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e57b12c030647c4986880384cac9d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patient Cases:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ConnectError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m prompt, test_cases, outcomes = build_few_shot_prompt(\n\u001b[32m      2\u001b[39m     features_a,\n\u001b[32m      3\u001b[39m     label_col=\u001b[33m\"\u001b[39m\u001b[33mIn-hospital_death_mean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     scoring=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m y_true, y_pred, y_scores = \u001b[43mevaluate_llm_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemma2:2b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cases\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/modules.py:135\u001b[39m, in \u001b[36mevaluate_llm_predictions\u001b[39m\u001b[34m(prompt, test_cases, outcomes, model, max_cases, verbose)\u001b[39m\n\u001b[32m    131\u001b[39m y_scores = []  \u001b[38;5;66;03m# for optional numeric scoring later\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, test_case \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(test_cases[:max_cases]), desc=\u001b[33m\"\u001b[39m\u001b[33mPatient Cases\u001b[39m\u001b[33m\"\u001b[39m, total = max_cases):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     prediction_raw = \u001b[43mquery_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m.lower().strip()\n\u001b[32m    137\u001b[39m     truth = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outcomes[i] == \u001b[33m\"\u001b[39m\u001b[33mdied\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# Parse prediction\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/modules.py:122\u001b[39m, in \u001b[36mquery_llm\u001b[39m\u001b[34m(prompt, test_case, model)\u001b[39m\n\u001b[32m    119\u001b[39m stream = chat(model=model, messages=messages, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    121\u001b[39m output = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/ollama/_client.py:163\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m      \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_client.py:868\u001b[39m, in \u001b[36mClient.stream\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[33;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m \u001b[33;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    855\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    856\u001b[39m     method=method,\n\u001b[32m    857\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    866\u001b[39m     extensions=extensions,\n\u001b[32m    867\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "prompt, test_cases, outcomes = build_few_shot_prompt(\n",
    "    features_a,\n",
    "    label_col=\"In-hospital_death_mean\",\n",
    "    scoring=False\n",
    ")\n",
    "\n",
    "y_true, y_pred, y_scores = evaluate_llm_predictions(prompt, test_cases, outcomes, model=\"gemma2:2b\", max_cases=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a081e1c-148b-426e-8789-a8a6baf94a47",
   "metadata": {},
   "source": [
    "## Q4.2 Embedding Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decc5685-051a-4201-b2a1-fd63e280c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_embedding(text, model='gemma2:2b'):\n",
    "    response = embeddings(model=model, prompt=text)\n",
    "    return response['embedding']\n",
    "\n",
    "def get_all(prompt, test_cases, model='gemma2:2b'):\n",
    "    return [get_patient_embedding(f\"{prompt}\\n\\n{t}\", model=model) for t in tqdm(test_cases, desc=\"Generating embeddings\")]\n",
    "\n",
    "\n",
    "######################### Training Data #########################\n",
    "# prompt, test_cases, outcomes = build_few_shot_prompt(\n",
    "#     features_a,\n",
    "#     label_col=\"In-hospital_death_mean\",\n",
    "#     scoring=False\n",
    "# )\n",
    "\n",
    "# embeddings_list = get_all(prompt, test_cases, model='gemma2:2b')\n",
    "\n",
    "# # Save as DataFrame for probe training\n",
    "# embedding_df = pd.DataFrame(embeddings_list)\n",
    "\n",
    "# # Add labels\n",
    "# embedding_df['label'] = features_a['In-hospital_death_mean'].copy()\n",
    "\n",
    "# # Save to csv \n",
    "# filename = Path(f\"embedding_df_Q42_a.csv\")\n",
    "# embedding_df.to_csv(notebooks_path / data_path / filename)\n",
    "\n",
    "# ######################## Validation Data #########################\n",
    "# prompt, test_cases, outcomes = build_few_shot_prompt(\n",
    "#     features_b,\n",
    "#     label_col=\"In-hospital_death_mean\",\n",
    "#     scoring=False\n",
    "# )\n",
    "\n",
    "# embeddings_list = get_all(prompt, test_cases, model='gemma2:2b')\n",
    "\n",
    "# # Save as DataFrame for probe training\n",
    "# embedding_df = pd.DataFrame(embeddings_list)\n",
    "\n",
    "# # Add labels\n",
    "# embedding_df['label'] = features_b['In-hospital_death_mean'].copy()\n",
    "\n",
    "# # Save to csv \n",
    "# filename = Path(f\"embedding_df_Q42_b.csv\")\n",
    "# embedding_df.to_csv(notebooks_path / data_path / filename)\n",
    "\n",
    "# ######################## Test Data #########################\n",
    "# prompt, test_cases, outcomes = build_few_shot_prompt(\n",
    "#     features_c,\n",
    "#     label_col=\"In-hospital_death_mean\",\n",
    "#     scoring=False\n",
    "# )\n",
    "\n",
    "# embeddings_list = get_all(prompt, test_cases, model='gemma2:2b')\n",
    "\n",
    "# # Save as DataFrame for probe training\n",
    "# embedding_df = pd.DataFrame(embeddings_list)\n",
    "\n",
    "# # Add labels\n",
    "# embedding_df['label'] = features_c['In-hospital_death_mean'].copy()\n",
    "\n",
    "# # Save to csv \n",
    "# filename = Path(f\"embedding_df_Q42_c.csv\")\n",
    "# embedding_df.to_csv(notebooks_path / data_path / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84639fc-878b-44d1-8e52-30671c4fe20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings df\n",
    "\n",
    "# train\n",
    "filename = Path(f\"embedding_df_Q42_a.csv\")\n",
    "embedding_df_a = pd.read_csv(notebooks_path / data_path / filename)\n",
    "filename = Path(f\"embedding_df_Q42_b.csv\")\n",
    "embedding_df_b = pd.read_csv(notebooks_path / data_path / filename)\n",
    "filename = Path(f\"embedding_df_Q42_c.csv\")\n",
    "embedding_df_c = pd.read_csv(notebooks_path / data_path / filename)\n",
    "del filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea1194bf-2220-4f02-b6c7-3b3946946671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3997]), torch.Size([3997, 2305]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "\n",
    "\n",
    "# ==== 1. Define Model ====\n",
    "class MortalityPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974d6a0f-67d5-42fc-9d67-9c53a80b28a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3862a4f25d0045ec89dccf1a91ec42d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Val AUROC: 0.5317, AUPRC: 0.1549\n",
      "[Epoch 2] Val AUROC: 0.5278, AUPRC: 0.1495\n",
      "[Epoch 3] Val AUROC: 0.5439, AUPRC: 0.1596\n",
      "[Epoch 4] Val AUROC: 0.5204, AUPRC: 0.1464\n",
      "[Epoch 5] Val AUROC: 0.5304, AUPRC: 0.1504\n",
      "[Epoch 6] Val AUROC: 0.5374, AUPRC: 0.1544\n",
      "[Epoch 7] Val AUROC: 0.5698, AUPRC: 0.1767\n",
      "[Epoch 8] Val AUROC: 0.5803, AUPRC: 0.1792\n",
      "[Epoch 9] Val AUROC: 0.5477, AUPRC: 0.1580\n",
      "[Epoch 10] Val AUROC: 0.5333, AUPRC: 0.1532\n",
      "[Epoch 11] Val AUROC: 0.5504, AUPRC: 0.1613\n",
      "[Epoch 12] Val AUROC: 0.5885, AUPRC: 0.1895\n",
      "[Epoch 13] Val AUROC: 0.5822, AUPRC: 0.1847\n",
      "[Epoch 14] Val AUROC: 0.6128, AUPRC: 0.1954\n",
      "[Epoch 15] Val AUROC: 0.6522, AUPRC: 0.2304\n",
      "[Epoch 16] Val AUROC: 0.5810, AUPRC: 0.1818\n",
      "[Epoch 17] Val AUROC: 0.5399, AUPRC: 0.1593\n",
      "[Epoch 18] Val AUROC: 0.5760, AUPRC: 0.1814\n",
      "[Epoch 19] Val AUROC: 0.6425, AUPRC: 0.2212\n",
      "[Epoch 20] Val AUROC: 0.6050, AUPRC: 0.2011\n",
      "✅ Finished training. Evaluating on test set...\n",
      "Test AUROC: 0.6050, AUPRC: 0.2011\n"
     ]
    }
   ],
   "source": [
    "# ==== 2. Training & Evaluation Logic ====\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_logits, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_logits.append(probs.cpu())\n",
    "            all_labels.append(yb.cpu())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_score = torch.cat(all_logits).numpy()\n",
    "    \n",
    "    # print(\"y_true:\", np.unique(y_true))\n",
    "    # print(\"y_score shape:\", y_score.shape, \"dtype:\", y_score.dtype)\n",
    "\n",
    "    return {\n",
    "        'AUROC': roc_auc_score(y_true, y_score),\n",
    "        'AUPRC': average_precision_score(y_true, y_score)\n",
    "    }\n",
    "    \n",
    "def train_model(X_train, y_train, X_val, y_val, X_test, y_test, model, \n",
    "                epochs=20, batch_size=32, lr=1e-3):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Wrap tensors in datasets\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    val_ds = TensorDataset(X_val, y_val)\n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    # Define model\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            # print(xb.shape)\n",
    "            xb, yb = xb.to(device), yb.to(device).float()\n",
    "            logits = model(xb)\n",
    "            # print(logits.device)\n",
    "            # return\n",
    "            # print(logits.shape)\n",
    "            # print(yb.shape)\n",
    "            # return\n",
    "            loss = loss_fn(logits, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "        print(f\"[Epoch {epoch+1}] Val AUROC: {val_metrics['AUROC']:.4f}, AUPRC: {val_metrics['AUPRC']:.4f}\")\n",
    "        # return\n",
    "\n",
    "    print(\"✅ Finished training. Evaluating on test set...\")\n",
    "    test_metrics = evaluate(model, test_loader, device)\n",
    "    print(f\"Test AUROC: {test_metrics['AUROC']:.4f}, AUPRC: {test_metrics['AUPRC']:.4f}\")\n",
    "\n",
    "    return model, test_metrics\n",
    "\n",
    "y_train = torch.tensor(embedding_df_a[\"label\"]).float()\n",
    "X_train = torch.tensor(embedding_df_a.iloc[:, :-1].values).float()\n",
    "y_val = torch.tensor(embedding_df_a[\"label\"]).float()\n",
    "X_val = torch.tensor(embedding_df_a.iloc[:, :-1].values).float()\n",
    "y_test = torch.tensor(embedding_df_a[\"label\"]).float()\n",
    "X_test = torch.tensor(embedding_df_a.iloc[:, :-1].values).float()\n",
    "model = MortalityPredictor(input_dim = X_train.shape[-1])\n",
    "model, test_metrics = train_model(X_train, y_train, X_val, y_val, X_test, y_test, model, epochs=20, batch_size=32, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce52d14-b889-4516-a240-6243b6372280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3b44840fd4c344e5875f1846e281c657": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_d7c0df61c3874eba9ed5be759a5c135d",
       "max": 20,
       "style": "IPY_MODEL_c64805d91c854eebb4369a95924860d8"
      }
     },
     "55fc00341cd944afa5d19a04363e9857": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e57b12c030647c4986880384cac9d91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7fcd806af1814500a781dd11412d312e",
        "IPY_MODEL_3b44840fd4c344e5875f1846e281c657",
        "IPY_MODEL_781b4a63c86d487183ce2d62183e0f5b"
       ],
       "layout": "IPY_MODEL_d92e3b7494784292a53abb0ccf1a5f51"
      }
     },
     "781b4a63c86d487183ce2d62183e0f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_55fc00341cd944afa5d19a04363e9857",
       "style": "IPY_MODEL_cf129b81723146d5ba11d47b6a068023",
       "value": " 0/20 [00:00&lt;?, ?it/s]"
      }
     },
     "7fcd806af1814500a781dd11412d312e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d87c682a36974ca29ac0cff8a8819815",
       "style": "IPY_MODEL_8066b8d42d5248d89fc7ad6a06e0aef1",
       "value": "Patient Cases:   0%"
      }
     },
     "8066b8d42d5248d89fc7ad6a06e0aef1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c64805d91c854eebb4369a95924860d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cf129b81723146d5ba11d47b6a068023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d7c0df61c3874eba9ed5be759a5c135d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d87c682a36974ca29ac0cff8a8819815": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d92e3b7494784292a53abb0ccf1a5f51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
