{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2405308b-b436-407c-8e71-c70884fc43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# override all pandas display limits\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4aa398f-7502-45e1-b2fd-c25a577c80ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a-filled.parquet -> set_a_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b.parquet -> set_b\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a.parquet -> set_a\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c-filled.parquet -> set_c_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c.parquet -> set_c\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b-filled.parquet -> set_b_filled\n"
     ]
    }
   ],
   "source": [
    "# load parquet files\n",
    "data_path = Path(\"../../data\")\n",
    "notebooks_path = Path(os.getcwd())\n",
    "data_dir = {}\n",
    "\n",
    "##unsafe\n",
    "# for file_path in list((notebooks_path / data_path).glob(\"*.parquet\")):\n",
    "#     print(f\"Reading {file_path}\")\n",
    "#     # retrieve the name of the file without the extension for all OS\n",
    "#     data = pd.read_parquet(file_path)\n",
    "#     # if \"Time\" in df.columns:\n",
    "#     #     df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "#     data_dir[str(file_path).replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0].replace(\"-\", \"_\")] = data\n",
    "\n",
    "for file_path in (notebooks_path / data_path).glob(\"set*.parquet\"):\n",
    "    var_name = file_path.stem.replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_parquet(file_path)\n",
    "    print(f\"Reading {file_path} -> {var_name}\")\n",
    "\n",
    "\n",
    "ID_vars = [\"PatientID\", \"Time\", \"RecordID\"] # TODO \n",
    "# stationary variables\n",
    "stationary_vars = [\"Age\", \"Gender\", \"Height\"] #, \"ICUType\"]\n",
    "# dynamic variables\n",
    "dynamic_vars = set_a.columns.difference(stationary_vars + ID_vars).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5ce5cc-b1d4-43bd-bd0a-93c2124d4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parquet_for_lstm(key, scaler=None, fit_scaler=False):\n",
    "    labelname = 'In-hospital_death'\n",
    "    df = globals()[f\"set_{key}_filled\"].copy()\n",
    "\n",
    "    # Sort and fill NaNs\n",
    "    df = df.sort_values([\"RecordID\", \"Time\"])\n",
    "    df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "    # raise NotImplementedError(\"Encode cathegories\")\n",
    "\n",
    "    # --- Fit scaler on all feature data if requested ---\n",
    "    if fit_scaler or scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[feature_cols])\n",
    "\n",
    "    # --- Apply scaling ---\n",
    "    df[feature_cols] = scaler.transform(df[feature_cols])\n",
    "\n",
    "    # Group by patient\n",
    "    X = []\n",
    "    y = []\n",
    "    for pid, group in df.groupby(\"RecordID\"):\n",
    "        group = group.sort_values(\"Time\")\n",
    "        X.append(group[feature_cols].values)\n",
    "        y.append(group[labelname].iloc[0])\n",
    "\n",
    "    X_tensor = torch.tensor(np.stack(X)).float()  # (n_patients, seq_len, n_features)\n",
    "    y_tensor = torch.tensor(y).float()            # (n_patients,)\n",
    "\n",
    "    return X_tensor, y_tensor, scaler  # return scaler for reuse on val/test\n",
    "\n",
    "feature_cols = dynamic_vars + stationary_vars\n",
    "X_train, y_train, fitted_scaler = preprocess_parquet_for_lstm(\"a\", fit_scaler = True)\n",
    "# len(preprocess_parquet_for_lstm(\"b\", scaler = fitted_scaler))\n",
    "X_val, y_val , _    = preprocess_parquet_for_lstm(\"b\", scaler = fitted_scaler)\n",
    "X_test, y_test , _  = preprocess_parquet_for_lstm(\"c\", scaler = fitted_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315afe46-bfcd-4841-8d2d-cc763d6511f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients, sequence_length, num_features  = X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4ce486f-cb67-4fca-a6fc-8ce42797b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load the pretrained Chronos model\n",
    "model_id = \"amazon/chronos-t5-small\"  # Example model; choose the one that fits your needs\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
    "    device_map=device,  # use \"cpu\" for CPU inference\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71dcd1cd-b6f6-4213-b00e-1cf960402a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m     pipeline.tokenizer.boundaries = pipeline.tokenizer.boundaries.to(feature_data.device)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         embeddings, _ = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m         embeddings_list.append(embeddings)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Stack embeddings: Shape will be (num_patients, num_features, embedding_dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/chronos/chronos.py:438\u001b[39m, in \u001b[36mChronosPipeline.embed\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[33;03mGet encoder embeddings for the given time series.\u001b[39;00m\n\u001b[32m    416\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m    provided, and the extra 1 is for EOS.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m context_tensor = \u001b[38;5;28mself\u001b[39m._prepare_and_validate_context(context=context)\n\u001b[32m    437\u001b[39m token_ids, attention_mask, tokenizer_state = (\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontext_input_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m )\n\u001b[32m    440\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.model.encode(\n\u001b[32m    441\u001b[39m     input_ids=token_ids.to(\u001b[38;5;28mself\u001b[39m.model.device),\n\u001b[32m    442\u001b[39m     attention_mask=attention_mask.to(\u001b[38;5;28mself\u001b[39m.model.device),\n\u001b[32m    443\u001b[39m ).cpu()\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings, tokenizer_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/chronos/chronos.py:227\u001b[39m, in \u001b[36mMeanScaleUniformBins.context_input_transform\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    224\u001b[39m token_ids, attention_mask, scale = \u001b[38;5;28mself\u001b[39m._input_transform(context=context)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_eos_token \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.model_type == \u001b[33m\"\u001b[39m\u001b[33mseq2seq\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     token_ids, attention_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_append_eos_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token_ids, attention_mask, scale\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/chronos/chronos.py:210\u001b[39m, in \u001b[36mMeanScaleUniformBins._append_eos_token\u001b[39m\u001b[34m(self, token_ids, attention_mask)\u001b[39m\n\u001b[32m    208\u001b[39m batch_size = token_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    209\u001b[39m eos_tokens = torch.full((batch_size, \u001b[32m1\u001b[39m), fill_value=\u001b[38;5;28mself\u001b[39m.config.eos_token_id)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m token_ids = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m eos_mask = torch.full((batch_size, \u001b[32m1\u001b[39m), fill_value=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    212\u001b[39m attention_mask = torch.concat((attention_mask, eos_mask), dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "X_tensor = X_train.clone().to(device)\n",
    "embeddings_list = []\n",
    "\n",
    "\n",
    "for feature_idx in range(num_features):\n",
    "    feature_data = X_tensor[:, :, feature_idx].to(pipeline.model.device)\n",
    "\n",
    "    # Fix: move tokenizer's boundaries to the same device\n",
    "    # pipeline.tokenizer.boundaries = pipeline.tokenizer.boundaries.to(feature_data.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = pipeline.embed(feature_data)\n",
    "        embeddings_list.append(embeddings)\n",
    "\n",
    "# Stack embeddings: Shape will be (num_patients, num_features, embedding_dim)\n",
    "embeddings_stack = torch.stack(embeddings_list, dim=1)\n",
    "\n",
    "# Aggregate embeddings across features, e.g., by averaging\n",
    "final_embeddings = embeddings_stack.mean(dim=1)  # Shape: (num_patients, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31cf6be9-1a85-4719-8288-d2cf65d825f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8018591-3479-4795-a0b8-1f78f35993f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0709c30b625d4de88baf38e1d4373e41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0a70b9ccdeac4602bff5e184ba5d2f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1bde656244c940009d3f8c18d146d480": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a5056e3a40794e8d887a229ba4c23c1f",
       "style": "IPY_MODEL_0a70b9ccdeac4602bff5e184ba5d2f5b",
       "value": "generation_config.json: 100%"
      }
     },
     "1fad083eea9d4a83978509bb914c21d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2ad3b148450746a0836f2870e34ddfa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "42de28551c5349c9856d9234bb47b94d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cc6ea9778a014882bda1a3f0096e4112",
        "IPY_MODEL_46f3efdba71f426d9b57c8a2817a9cb8",
        "IPY_MODEL_7c2a4058e0a94349a8519e21450616e2"
       ],
       "layout": "IPY_MODEL_2ad3b148450746a0836f2870e34ddfa6"
      }
     },
     "448ac67252874d5586c7aeb53fb50da4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "46f3efdba71f426d9b57c8a2817a9cb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0709c30b625d4de88baf38e1d4373e41",
       "max": 184632480,
       "style": "IPY_MODEL_8468ba0df6b0482187c875bfa25a90a0",
       "value": 184632480
      }
     },
     "544ba546861d406bbfcc522b5f89bebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "58e9fbd68afb4f5cb97ea5320cc5ed4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7ae6d41da1be4c4995c8c00d2266d7cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7c2a4058e0a94349a8519e21450616e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b0fed4b2fc8b488ca17b8a4d6983e244",
       "style": "IPY_MODEL_86c5a105aeb84991a98a429596b15de7",
       "value": " 185M/185M [00:00&lt;00:00, 370MB/s]"
      }
     },
     "8468ba0df6b0482187c875bfa25a90a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "86c5a105aeb84991a98a429596b15de7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8708db0ff25d4fcf88b8cf31d0a39b5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ac31ef47cba94b52990c958919557918",
       "max": 1113,
       "style": "IPY_MODEL_f4654c28d0654527bd5a20d6dfd8e6aa",
       "value": 1113
      }
     },
     "882d639317d640e98cdd8844e00f419c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "89026b6467ee42b1a794171cb976c234": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7ae6d41da1be4c4995c8c00d2266d7cb",
       "style": "IPY_MODEL_448ac67252874d5586c7aeb53fb50da4",
       "value": "config.json: 100%"
      }
     },
     "91b4999ab9aa49c8acadb507aaee3b94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_882d639317d640e98cdd8844e00f419c",
       "max": 142,
       "style": "IPY_MODEL_58e9fbd68afb4f5cb97ea5320cc5ed4e",
       "value": 142
      }
     },
     "a0a63520ef854d0f9d71dac0c3ea2ef6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d23b61cc368b4cc491235311bd931247",
       "style": "IPY_MODEL_544ba546861d406bbfcc522b5f89bebd",
       "value": " 1.11k/1.11k [00:00&lt;00:00, 58.4kB/s]"
      }
     },
     "a5056e3a40794e8d887a229ba4c23c1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ac31ef47cba94b52990c958919557918": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "acc3603ffe5040c6abe4c0b235808c3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_89026b6467ee42b1a794171cb976c234",
        "IPY_MODEL_8708db0ff25d4fcf88b8cf31d0a39b5c",
        "IPY_MODEL_a0a63520ef854d0f9d71dac0c3ea2ef6"
       ],
       "layout": "IPY_MODEL_d9d888c0ca8c484181b78533f17e861f"
      }
     },
     "b0fed4b2fc8b488ca17b8a4d6983e244": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b80b067922d9425a923e5559b705fb68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1bde656244c940009d3f8c18d146d480",
        "IPY_MODEL_91b4999ab9aa49c8acadb507aaee3b94",
        "IPY_MODEL_f867be5ea1a545bf91a48b6b5b98e09a"
       ],
       "layout": "IPY_MODEL_f0548dd088a74feaa789601e44a7e7eb"
      }
     },
     "bfd160356b71498797dd66e836d00456": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc6ea9778a014882bda1a3f0096e4112": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1fad083eea9d4a83978509bb914c21d6",
       "style": "IPY_MODEL_e97d4ffb3c374aae937da28071ff741e",
       "value": "model.safetensors: 100%"
      }
     },
     "d1b3d9b8cc8b43759de20ed9e3105e42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d23b61cc368b4cc491235311bd931247": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d9d888c0ca8c484181b78533f17e861f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e97d4ffb3c374aae937da28071ff741e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f0548dd088a74feaa789601e44a7e7eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4654c28d0654527bd5a20d6dfd8e6aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f867be5ea1a545bf91a48b6b5b98e09a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bfd160356b71498797dd66e836d00456",
       "style": "IPY_MODEL_d1b3d9b8cc8b43759de20ed9e3105e42",
       "value": " 142/142 [00:00&lt;00:00, 7.05kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
