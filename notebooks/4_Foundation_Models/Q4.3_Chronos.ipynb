{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2405308b-b436-407c-8e71-c70884fc43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, IterableDataset\n",
    "from chronos import BaseChronosPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix,\n",
    "    roc_auc_score, precision_recall_curve,\n",
    "    roc_curve, auc\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from modules import * \n",
    "\n",
    "# override all pandas display limits\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4aa398f-7502-45e1-b2fd-c25a577c80ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a-filled.parquet -> set_a_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b.parquet -> set_b\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-a.parquet -> set_a\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c-filled.parquet -> set_c_filled\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-c.parquet -> set_c\n",
      "Reading /home/pbaertschi/ICU-TimeSeries-Mortality-Prediction/notebooks/4_Foundation_Models/../../data/set-b-filled.parquet -> set_b_filled\n"
     ]
    }
   ],
   "source": [
    "# load parquet files\n",
    "data_path = Path(\"../../data\")\n",
    "notebooks_path = Path(os.getcwd())\n",
    "data_dir = {}\n",
    "\n",
    "##unsafe\n",
    "# for file_path in list((notebooks_path / data_path).glob(\"*.parquet\")):\n",
    "#     print(f\"Reading {file_path}\")\n",
    "#     # retrieve the name of the file without the extension for all OS\n",
    "#     data = pd.read_parquet(file_path)\n",
    "#     # if \"Time\" in df.columns:\n",
    "#     #     df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "#     data_dir[str(file_path).replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0].replace(\"-\", \"_\")] = data\n",
    "\n",
    "for file_path in (notebooks_path / data_path).glob(\"set*.parquet\"):\n",
    "    var_name = file_path.stem.replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_parquet(file_path)\n",
    "    print(f\"Reading {file_path} -> {var_name}\")\n",
    "\n",
    "\n",
    "ID_vars = [\"PatientID\", \"Time\", \"RecordID\"] # TODO \n",
    "# stationary variables\n",
    "stationary_vars = [\"Age\", \"Gender\", \"Height\"] #, \"ICUType\"]\n",
    "# dynamic variables\n",
    "dynamic_vars = set_a.columns.difference(stationary_vars + ID_vars + ['In-hospital_death']).tolist()\n",
    "\n",
    "feature_cols = dynamic_vars + stationary_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5ce5cc-b1d4-43bd-bd0a-93c2124d4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parquet_for_lstm(key, scaler=None, fit_scaler=False):\n",
    "    labelname = 'In-hospital_death'\n",
    "    df = globals()[f\"set_{key}_filled\"].copy()\n",
    "\n",
    "    # Sort and fill NaNs\n",
    "    df = df.sort_values([\"RecordID\", \"Time\"])\n",
    "    df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "    # raise NotImplementedError(\"Encode cathegories\")\n",
    "\n",
    "    # --- Fit scaler on all feature data if requested ---\n",
    "    if fit_scaler or scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[feature_cols])\n",
    "\n",
    "    # --- Apply scaling ---\n",
    "    df[feature_cols] = scaler.transform(df[feature_cols])\n",
    "\n",
    "    # Group by patient\n",
    "    X = []\n",
    "    y = []\n",
    "    for pid, group in df.groupby(\"RecordID\"):\n",
    "        group = group.sort_values(\"Time\")\n",
    "        X.append(group[feature_cols].values)\n",
    "        y.append(group[labelname].iloc[0])\n",
    "\n",
    "    X_tensor = torch.tensor(np.stack(X)).float()  # (n_patients, seq_len, n_features)\n",
    "    y_tensor = torch.tensor(y).float()            # (n_patients,)\n",
    "\n",
    "    return X_tensor, y_tensor, scaler  # return scaler for reuse on val/test\n",
    "\n",
    "\n",
    "X_train, y_train, fitted_scaler = preprocess_parquet_for_lstm(\"a\", fit_scaler = True)\n",
    "# len(preprocess_parquet_for_lstm(\"b\", scaler = fitted_scaler))\n",
    "X_val, y_val , _    = preprocess_parquet_for_lstm(\"b\", scaler = fitted_scaler)\n",
    "X_test, y_test , _  = preprocess_parquet_for_lstm(\"c\", scaler = fitted_scaler)\n",
    "\n",
    "\n",
    "# extract dimensions\n",
    "num_patients, sequence_length, num_features  = X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ce486f-cb67-4fca-a6fc-8ce42797b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load the pretrained Chronos model\n",
    "model_id = \"amazon/chronos-t5-small\"  # Example model; choose the one that fits your needs\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
    "    device_map=device,  # use \"cpu\" for CPU inference\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "# Manually move tokenizer boundaries to match model device\n",
    "pipeline.tokenizer.boundaries = pipeline.tokenizer.boundaries.to(pipeline.model.device)\n",
    "\n",
    "# Fix Chronos tokenizer device mismatch when appending EOS token\n",
    "def patched_append_eos_token(self, token_ids, attention_mask):\n",
    "    device = token_ids.device\n",
    "    batch_size = token_ids.shape[0]\n",
    "    eos_tokens = torch.full((batch_size, 1), fill_value=self.config.eos_token_id, device=device)\n",
    "    eos_mask = torch.full((batch_size, 1), fill_value=True, device=device)\n",
    "    token_ids = torch.concat((token_ids, eos_tokens), dim=1)\n",
    "    attention_mask = torch.concat((attention_mask, eos_mask), dim=1)\n",
    "    return token_ids, attention_mask\n",
    "\n",
    "# Patch the method\n",
    "pipeline.tokenizer._append_eos_token = patched_append_eos_token.__get__(pipeline.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c469730-ddbb-432e-9781-ecbdf082bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_embeddings = get_chronos_embeddings(X_train, num_features, pipeline, return_stack = False)\n",
    "# X_val_embeddings = get_chronos_embeddings(X_val, num_features, pipeline, return_stack = False)\n",
    "# X_test_embeddings = get_chronos_embeddings(X_test, num_features, pipeline, return_stack = False)\n",
    "# torch.save(X_train_embeddings, notebooks_path / data_path / Path('X_train_embeddings_Q431.pt'))\n",
    "# torch.save(X_val_embeddings, notebooks_path / data_path / Path('X_val_embeddings_Q431.pt'))\n",
    "# torch.save(X_test_embeddings, notebooks_path / data_path / Path('X_test_embeddings_Q431.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34425ea1-b1bb-4a59-a2b9-d743f8ecc7a4",
   "metadata": {},
   "source": [
    "## Part 1: fixed pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cf6be9-1a85-4719-8288-d2cf65d825f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== 1. Define Model ====\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes = 1):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(input_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_flat = x.view(x.shape[0], -1) # flatten all dimensions but batch\n",
    "        # print(x_flat.shape)\n",
    "        return self.layer(x_flat).squeeze(-1)\n",
    "\n",
    "X_train_embeddings = torch.load(notebooks_path / data_path / Path('X_train_embeddings_Q431.pt')).float()\n",
    "X_val_embeddings = torch.load(notebooks_path / data_path / Path('X_val_embeddings_Q431.pt')).float()\n",
    "X_test_embeddings = torch.load(notebooks_path / data_path / Path('X_test_embeddings_Q431.pt')).float()\n",
    "\n",
    "x = X_train_embeddings[0].unsqueeze(0)\n",
    "\n",
    "lp = LinearProbe(input_dim = x.view(1, -1).shape[-1])\n",
    "lp(x).shape\n",
    "# lpP = LinearProbe(input_dim=, num_segments ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9e9739-5b00-4f1e-a6b1-2abc8b433aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7b96a7d88f4a5bbd14d25f57353f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Val AUROC: 0.7448, AUPRC: 0.3624\n",
      "[Epoch 2] Val AUROC: 0.7600, AUPRC: 0.3811\n",
      "[Epoch 3] Val AUROC: 0.7718, AUPRC: 0.3973\n",
      "[Epoch 4] Val AUROC: 0.7786, AUPRC: 0.4091\n",
      "[Epoch 5] Val AUROC: 0.7810, AUPRC: 0.4139\n",
      "[Epoch 6] Val AUROC: 0.7850, AUPRC: 0.4241\n",
      "[Epoch 7] Val AUROC: 0.7866, AUPRC: 0.4258\n",
      "[Epoch 8] Val AUROC: 0.7879, AUPRC: 0.4289\n",
      "[Epoch 9] Val AUROC: 0.7896, AUPRC: 0.4337\n",
      "[Epoch 10] Val AUROC: 0.7911, AUPRC: 0.4371\n",
      "[Epoch 11] Val AUROC: 0.7919, AUPRC: 0.4397\n",
      "[Epoch 12] Val AUROC: 0.7926, AUPRC: 0.4410\n",
      "[Epoch 13] Val AUROC: 0.7938, AUPRC: 0.4429\n",
      "[Epoch 14] Val AUROC: 0.7947, AUPRC: 0.4445\n",
      "[Epoch 15] Val AUROC: 0.7950, AUPRC: 0.4453\n",
      "[Epoch 16] Val AUROC: 0.7952, AUPRC: 0.4467\n",
      "[Epoch 17] Val AUROC: 0.7966, AUPRC: 0.4487\n",
      "[Epoch 18] Val AUROC: 0.7967, AUPRC: 0.4471\n",
      "[Epoch 19] Val AUROC: 0.7971, AUPRC: 0.4496\n",
      "[Epoch 20] Val AUROC: 0.7974, AUPRC: 0.4493\n",
      "✅ Finished training. Evaluating on test set...\n",
      "Test AUROC: 0.7832, AUPRC: 0.4124\n"
     ]
    }
   ],
   "source": [
    "# ==== 2. Training & Evaluation Logic ====\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_logits, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_logits.append(probs.cpu())\n",
    "            all_labels.append(yb.cpu())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_score = torch.cat(all_logits).numpy()\n",
    "    \n",
    "    # print(\"y_true:\", np.unique(y_true))\n",
    "    # print(\"y_score shape:\", y_score.shape, \"dtype:\", y_score.dtype)\n",
    "\n",
    "    return {\n",
    "        'AUROC': roc_auc_score(y_true, y_score),\n",
    "        'AUPRC': average_precision_score(y_true, y_score)\n",
    "    }\n",
    "    \n",
    "def train_model(X_train, y_train, X_val, y_val, X_test, y_test, model, \n",
    "                epochs=20, batch_size=32, lr=1e-3):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Wrap tensors in datasets\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    val_ds = TensorDataset(X_val, y_val)\n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    # Define model\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            # print(xb.shape)\n",
    "            xb, yb = xb.to(device), yb.to(device).float()\n",
    "            logits = model(xb)\n",
    "            # print(logits.device)\n",
    "            # return\n",
    "            # print(logits.shape)\n",
    "            # print(yb.shape)\n",
    "            # return\n",
    "            loss = loss_fn(logits, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "        print(f\"[Epoch {epoch+1}] Val AUROC: {val_metrics['AUROC']:.4f}, AUPRC: {val_metrics['AUPRC']:.4f}\")\n",
    "        # return\n",
    "\n",
    "    print(\"✅ Finished training. Evaluating on test set...\")\n",
    "    test_metrics = evaluate(model, test_loader, device)\n",
    "    print(f\"Test AUROC: {test_metrics['AUROC']:.4f}, AUPRC: {test_metrics['AUPRC']:.4f}\")\n",
    "\n",
    "    return model, test_metrics\n",
    "\n",
    "model = LinearProbe(input_dim = x.view(1, -1).shape[-1])\n",
    "# print(x.view(1, -1).shape[-1])\n",
    "model, test_metrics = train_model(X_train_embeddings, y_train, X_val_embeddings, y_val, X_test_embeddings, y_test, model, epochs=20, batch_size=32, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc7f984-db85-4cb4-a7db-09b94b0bb25a",
   "metadata": {},
   "source": [
    "## Part 2: learnt pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e4c05f-e1ef-43fb-8d99-aad689d07b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first we need to get the stacked embeddings -> these are very memory intensive so we can only have one in memory at a time\n",
    "# X_train_embeddings = get_chronos_embeddings(X_train, num_features, pipeline, return_stack = True)\n",
    "# torch.save(X_train_embeddings, notebooks_path / data_path / Path('X_train_embeddings_Q431_stacked.pt'))\n",
    "# del X_train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42431002-641a-4873-b481-c117fb0f1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_embeddings = get_chronos_embeddings(X_val, num_features, pipeline, return_stack = True)\n",
    "# torch.save(X_val_embeddings, notebooks_path / data_path / Path('X_val_embeddings_Q431_stacked.pt'))\n",
    "# del X_val_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d20e46-2ffd-4be4-99e0-79c932ecf18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_embeddings = get_chronos_embeddings(X_test, num_features, pipeline, return_stack = True)\n",
    "# torch.save(X_test_embeddings, notebooks_path / data_path / Path('X_test_embeddings_Q431_stacked.pt'), _use_new_zipfile_serialization=False)\n",
    "# del X_test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb12a3b-8307-48d2-ba98-3d8b76e08472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_train, notebooks_path / data_path / \"y_train_Q431.pt\")\n",
    "# torch.save(y_test, notebooks_path /data_path / \"y_test_Q431.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e18a9f99-28f8-458a-a386-29ec972777d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model dimensions   \n",
    "X_embeddings = torch.load(notebooks_path / data_path / Path('X_train_embeddings_Q431_stacked.pt'))\n",
    "patients, num_segments, tokens, features = X_embeddings.shape\n",
    "# extract tensor to test the shape\n",
    "X_tensor = X_embeddings[0].unsqueeze(0)\n",
    "del X_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ac34ff-2069-4ed1-a042-ab302c268130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorChunkDataset(IterableDataset):\n",
    "    def __init__(self, file_path, batch_size, label_file=None):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "        self.label_file = label_file\n",
    "\n",
    "    def __iter__(self):\n",
    "        data = torch.load(self.file_path, map_location='cpu')  # Lazy load on each worker\n",
    "        num_batches = data.size(0) // self.batch_size\n",
    "        for i in range(num_batches):\n",
    "            x_batch = data[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            if self.label_file:\n",
    "                labels = torch.load(self.label_file, map_location='cpu')\n",
    "                y_batch = labels[i*self.batch_size:(i+1)*self.batch_size]\n",
    "                yield x_batch, y_batch\n",
    "            else:\n",
    "                yield x_batch\n",
    "\n",
    "def train_model(model, train_loader, device, epochs=10, lr=1e-3):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # assuming binary classification\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device).float()\n",
    "\n",
    "            # flatten (sequence, feature_embedding) -> -1\n",
    "            # x_batch = x_batch.view(x_batch.size(0), x_batch.size(1), -1)\n",
    "\n",
    "            logits = model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device).float()\n",
    "        x_batch = x_batch.view(x_batch.size(0), x_batch.size(1), -1)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        all_preds.append(probs.cpu())\n",
    "        all_labels.append(y_batch.cpu())\n",
    "\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_prob = torch.cat(all_preds).numpy()\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    prc_auc = auc(recall, precision)\n",
    "\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PRC AUC: {prc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot PRC Curve\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f\"PRC curve (AUC = {prc_auc:.2f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2adbc37-21c6-4faa-85c7-7e6a5ee8dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class LinearProbe_LearnablePooling(nn.Module): \n",
    "    def __init__(self, input_dim, num_segments, n_classes = 1):\n",
    "        super().__init__()\n",
    "        # pooling weights \n",
    "        self.segment_weights = nn.Parameter(torch.randn(1, num_segments, 1, 1))\n",
    "\n",
    "        # linear probe\n",
    "        self.layer = nn.Linear(input_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # weight\n",
    "        batch_size = x.shape[0]\n",
    "        # Shape: (1, num_segments, 1) -> (batch_size, num_segments, 1, 1)\n",
    "        weights = F.softmax(self.segment_weights, dim=1)  # softmax over segments\n",
    "        # print(weights.shape, x.shape)\n",
    "        # raise Exception()\n",
    "        weighted = x * weights  # broadcasting over batch and feature dim\n",
    "        # print(weighted.shape)\n",
    "        pooled = weighted.sum(dim=1).view(batch_size, -1)  # sum over segments\n",
    "        # print(pooled.shape)\n",
    "        return self.layer(pooled).squeeze(-1)\n",
    "\n",
    "model = LinearProbe_LearnablePooling(input_dim = tokens * features, num_segments = num_segments)\n",
    "print(model(X_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3314e43f-28d7-4e06-bcc9-0ab275242d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7ab3e0d28d498683f1d38da8f49224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 51.1650\n",
      "Epoch 2/10, Loss: 49.1801\n",
      "Epoch 3/10, Loss: 48.4213\n",
      "Epoch 4/10, Loss: 47.7743\n",
      "Epoch 5/10, Loss: 47.1977\n",
      "Epoch 6/10, Loss: 46.6709\n",
      "Epoch 7/10, Loss: 46.1814\n",
      "Epoch 8/10, Loss: 45.7218\n",
      "Epoch 9/10, Loss: 45.2871\n",
      "Epoch 10/10, Loss: 44.8740\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (41) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m train_model(model, train_loader, device)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# eval \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_loader, device)\u001b[39m\n\u001b[32m     53\u001b[39m y_batch = y_batch.to(device).float()\n\u001b[32m     54\u001b[39m x_batch = x_batch.view(x_batch.size(\u001b[32m0\u001b[39m), x_batch.size(\u001b[32m1\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m probs = torch.sigmoid(logits)\n\u001b[32m     59\u001b[39m all_preds.append(probs.cpu())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mLinearProbe_LearnablePooling.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     14\u001b[39m weights = F.softmax(\u001b[38;5;28mself\u001b[39m.segment_weights, dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# softmax over segments\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# print(weights.shape, x.shape)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# raise Exception()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m weighted = \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m  \u001b[38;5;66;03m# broadcasting over batch and feature dim\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# print(weighted.shape)\u001b[39;00m\n\u001b[32m     19\u001b[39m pooled = weighted.sum(dim=\u001b[32m1\u001b[39m).view(batch_size, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# sum over segments\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (32) must match the size of tensor b (41) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train_file = notebooks_path / data_path / \"X_train_embeddings_Q431_stacked.pt\"\n",
    "train_labels = notebooks_path / data_path / \"y_train_Q431.pt\"\n",
    "test_file = notebooks_path / data_path / \"X_test_embeddings_Q431_stacked.pt\"\n",
    "test_labels = notebooks_path / data_path / \"y_test_Q431.pt\"\n",
    "\n",
    "# hypers\n",
    "batch_size = 32\n",
    "\n",
    "# streamed train dataset\n",
    "train_dataset = TensorChunkDataset(train_file, batch_size=batch_size, label_file=train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=None)\n",
    "\n",
    "# stream test dataset\n",
    "test_dataset = TensorChunkDataset(test_file, batch_size=batch_size, label_file=test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=None)\n",
    "\n",
    "\n",
    "model = LinearProbe_LearnablePooling(input_dim = tokens * features, num_segments = num_segments)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# train\n",
    "train_model(model, train_loader, device)\n",
    "# eval \n",
    "evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34e40c-31c1-448d-9dab-1954c65e7f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
