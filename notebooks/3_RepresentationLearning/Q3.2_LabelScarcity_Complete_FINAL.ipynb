{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb36bce7",
   "metadata": {},
   "source": [
    "# Q3.2 - Simulating Label Scarcity\n",
    "This notebook combines encoder pretraining, linear probing, and supervised LSTM models under label scarcity conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b12b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301088c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (196000, 43) Val: (196000, 43) Test: (196000, 43)\n"
     ]
    }
   ],
   "source": [
    "# def load_data():\n",
    "#     os.chdir(\"/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data\")\n",
    "#     df_train = pd.read_parquet(\"set-a-filled.parquet\")\n",
    "#     df_val = pd.read_parquet(\"set-b-filled.parquet\")\n",
    "#     df_test = pd.read_parquet(\"set-c-filled.parquet\")\n",
    "    \n",
    "#     #print(df_train.head())\n",
    "#     #print(df_val.head())\n",
    "#     #print(df_test.head())\n",
    "    \n",
    "\n",
    "#     labels_train = pd.read_csv(\"Outcomes-a.txt\", sep=',')[['RecordID', 'In-hospital_death']]\n",
    "#     labels_val = pd.read_csv(\"Outcomes-b.txt\", sep=',')[['RecordID', 'In-hospital_death']]\n",
    "#     labels_test = pd.read_csv(\"Outcomes-c.txt\", sep=',')[['RecordID', 'In-hospital_death']]\n",
    "\n",
    "#     return (df_train.drop(columns = ['In-hospital_death', 'ICUType']), labels_train), (df_val.drop(columns = ['In-hospital_death', 'ICUType']), labels_val), (df_test.drop(columns = ['In-hospital_death', 'ICUType']), labels_test)\n",
    "\n",
    "# os.chdir(\"/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data\")\\\n",
    "os.chdir(\"../../data\")\n",
    "# Load parquet data\n",
    "df_a = pd.read_parquet(\"set-a-filled.parquet\").drop(columns = ['ICUType'])\n",
    "df_b = pd.read_parquet(\"set-b-filled.parquet\").drop(columns = ['ICUType'])\n",
    "df_c = pd.read_parquet(\"set-c-filled.parquet\").drop(columns = ['ICUType'])\n",
    "\n",
    "print(\"Train:\", df_a.shape, \"Val:\", df_b.shape, \"Test:\", df_c.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e6dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (last_hidden_state, last_cell_state) = self.encoder(x)\n",
    "\n",
    "        decoder_input = torch.zeros(x.size(0), x.size(1), self.hparams.hidden_size, device=x.device)\n",
    "\n",
    "        decoder_output, _ = self.decoder(decoder_input, (last_hidden_state, last_cell_state))\n",
    "\n",
    "        output_seq = self.output_layer(decoder_output)  # shape: (batch, seq_len, input_size)\n",
    "        return output_seq\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_seq, _ = batch\n",
    "        output_seq = self(input_seq)\n",
    "        loss = self.loss_fn(output_seq, input_seq)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_seq, _ = batch\n",
    "        output_seq = self(input_seq)\n",
    "        loss = self.loss_fn(output_seq, input_seq)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3a4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_cols,\n",
    "        batch_size=32,\n",
    "        k_folds=None,  # set this to an int (e.g., 5) to activate k-fold\n",
    "        fold_index=0    # index of current fold\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "        self.batch_size = batch_size\n",
    "        self.k_folds = k_folds\n",
    "        self.fold_index = fold_index\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_parquet_for_lstm(self, df, scaler=None, fit_scaler=False):\n",
    "        labelname = 'In-hospital_death'\n",
    "        \n",
    "\n",
    "    \n",
    "            \n",
    "    \n",
    "        # Sort and fill NaNs\n",
    "        df = df.sort_values([\"RecordID\", \"Time\"])\n",
    "        df[self.feature_cols] = df[self.feature_cols].fillna(0)\n",
    "    \n",
    "        # Replace -1 with 0 in binary categorical feature\n",
    "        if \"MechVent\" in df.columns:\n",
    "            df[\"MechVent\"] = df[\"MechVent\"].replace(-1, 0)\n",
    "    \n",
    "        # One-hot encode Gender, drop last column to avoid multicollinearity\n",
    "        if \"Gender\" in df.columns:\n",
    "            gender_dummies = pd.get_dummies(df[\"Gender\"], prefix=\"Gender\", dtype=float)\n",
    "            gender_dummies = gender_dummies.iloc[:, :-1]  # drop last dummy column\n",
    "            df = df.drop(columns=[\"Gender\"])\n",
    "            df = pd.concat([df, gender_dummies], axis=1)\n",
    "    \n",
    "        # Update feature columns after dummy encoding\n",
    "        current_feature_cols = [col for col in df.columns if col in self.feature_cols or col.startswith(\"Gender_\")]\n",
    "    \n",
    "        # Extract numerical columns for scaling\n",
    "        numerical = [f for f in current_feature_cols if f not in [\"MechVent\", labelname] and not f.startswith(\"Gender_\")]\n",
    "    \n",
    "        # Fit or reuse scaler\n",
    "        if fit_scaler or scaler is None:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[numerical])\n",
    "    \n",
    "        # Apply scaling\n",
    "        df[numerical] = scaler.transform(df[numerical])\n",
    "    \n",
    "        # Group by RecordID\n",
    "        X, y = [], []\n",
    "        for pid, group in df.groupby(\"RecordID\"):\n",
    "            \n",
    "            group = group.sort_values(\"Time\")\n",
    "            X.append(group[current_feature_cols].values)\n",
    "            label = group[labelname].iloc[0]\n",
    "            # if label not in [0, 1]:\n",
    "            #     raise ValueError(f\"Unexpected label {label} for patient {pid}. Expected binary labels only.\")\n",
    "            y.append(int(label))\n",
    "        #print(current_feature_cols)\n",
    "        #print(pd.DataFrame(np.stack(X)).head())\n",
    "        X_tensor = torch.tensor(np.stack(X)).float()\n",
    "        y_tensor = torch.tensor(y).float()\n",
    "    \n",
    "        return X_tensor, y_tensor, scaler\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # # Load training and validation sets and stack them\n",
    "        # X_trainval_a, y_trainval_a, fitted_scaler = self.preprocess_parquet_for_lstm(\"a\", fit_scaler=True)\n",
    "        # X_trainval_b, y_trainval_b, _ = self.preprocess_parquet_for_lstm(\"b\", scaler=fitted_scaler)\n",
    "\n",
    "        # # Stack A and B\n",
    "        # X_trainval = torch.cat([X_trainval_a, X_trainval_b], dim=0)\n",
    "        # y_trainval = torch.cat([y_trainval_a, y_trainval_b], dim=0)\n",
    "\n",
    "        # if self.k_folds:\n",
    "        #     kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n",
    "        #     indices = list(kf.split(X_trainval))\n",
    "\n",
    "        #     train_idx, val_idx = indices[self.fold_index]\n",
    "        #     self.X_train, self.y_train = X_trainval[train_idx], y_trainval[train_idx]\n",
    "        #     self.X_val, self.y_val     = X_trainval[val_idx], y_trainval[val_idx]\n",
    "        # else:\n",
    "        #     self.X_train, self.y_train = X_trainval_a, y_trainval_a\n",
    "        #     self.X_val, self.y_val     = X_trainval_b, y_trainval_b\n",
    "\n",
    "        # self.X_test, self.y_test, _ = self.preprocess_parquet_for_lstm(\"c\", scaler=fitted_scaler)\n",
    "\n",
    "        # self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        # self.val_dataset   = TensorDataset(self.X_val, self.y_val)\n",
    "        # self.test_dataset  = TensorDataset(self.X_test, self.y_test)\n",
    "        self.X_train, self.y_train, fitted_scaler = self.preprocess_parquet_for_lstm(df_a, fit_scaler = True)\n",
    "        self.X_val, self.y_val , _    = self.preprocess_parquet_for_lstm(df_b, scaler = fitted_scaler)\n",
    "        self.X_test, self.y_test , _  = self.preprocess_parquet_for_lstm(df_c, scaler = fitted_scaler)\n",
    "\n",
    "        self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        self.val_dataset   = TensorDataset(self.X_val, self.y_val)\n",
    "        self.test_dataset  = TensorDataset(self.X_test, self.y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf77fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, dataloader):\n",
    "    model.eval()\n",
    "    embeddings, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            _, (last_hidden_state, _) = model.encoder(x)\n",
    "            z = last_hidden_state[-1]\n",
    "            embeddings.append(z.cpu().numpy())\n",
    "            labels.append(y.cpu().numpy())\n",
    "    return np.vstack(embeddings), np.concatenate(labels)\n",
    "\n",
    "def train_and_eval_probe(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    probs = clf.predict_proba(X_test)[:, 1]\n",
    "    auroc = roc_auc_score(y_test, probs)\n",
    "    auprc = average_precision_score(y_test, probs)\n",
    "    print(f\"Linear Probe:\\n AuROC: {auroc:.4f},\\n AuPRC: {auprc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970ec041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Store test outputs manually\n",
    "        self.test_probs = []\n",
    "        self.test_targets = []\n",
    "\n",
    "        # Prediction threshold\n",
    "        self.prediction_threshold = 0.5\n",
    "        self.clear_after_testing = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run input through the LSTM\n",
    "        _, (hidden_state, _) = self.lstm(x)  # lstm_output, (hidden_state, cell_state)\n",
    "\n",
    "        # Take the last layer's hidden state (for stacked LSTM)\n",
    "        last_hidden = hidden_state[-1]  # shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Pass through the classification head\n",
    "        logits = self.classifier(last_hidden)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        acc = (preds.int() == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        # print(torch.unique(log\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        # Store results for epoch-end metrics\n",
    "        self.test_probs.append(probs.detach().cpu())\n",
    "        self.test_targets.append(y.detach().cpu())\n",
    "\n",
    "        return loss \n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "            probs = torch.cat(self.test_probs).cpu()\n",
    "            targets = torch.cat(self.test_targets).cpu()\n",
    "            preds = (probs > 0.5).int()\n",
    "            \n",
    "            # Convert both to int numpy arrays\n",
    "            targets_np = targets.int().numpy()\n",
    "            preds_np = preds.numpy()\n",
    "\n",
    "            if self.clear_after_testing: \n",
    "                self.test_probs.clear()\n",
    "                self.test_targets.clear()\n",
    "    \n",
    "            # --- Confusion Matrix ---\n",
    "            cm = confusion_matrix(targets_np, preds_np)\n",
    "            disp_cm = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "            disp_cm.plot(cmap='Blues')\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.show()\n",
    "    \n",
    "            # --- ROC Curve ---\n",
    "            auc = roc_auc_score(targets_np, probs.numpy())\n",
    "            RocCurveDisplay.from_predictions(targets, probs)\n",
    "            plt.title(f\"ROC Curve (AuROC = {auc:.3f})\")\n",
    "            plt.show()\n",
    "    \n",
    "            # --- Precision-Recall Curve ---\n",
    "            auprc = average_precision_score(targets_np, probs.numpy())\n",
    "            PrecisionRecallDisplay.from_predictions(targets, probs)\n",
    "            plt.title(f\"Precision-Recall Curve (AuPRC = {auprc:.3f})\")\n",
    "            plt.show()\n",
    "    \n",
    "            # --- Metrics ---\n",
    "            acc = (preds == targets).float().mean()\n",
    "            self.log(\"test_acc\", acc)\n",
    "            self.log(\"test_auroc\", auc)\n",
    "            self.log(\"test_auprc\", auprc)\n",
    "    \n",
    "            print(f\"\\nTest Accuracy : {acc:.4f}\")\n",
    "            print(f\"Test AuROC    : {auc:.4f}\")\n",
    "            print(f\"Test AuPRC    : {auprc:.4f}\")\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "    def tune_threshold_min_fnr(self):\n",
    "        \"\"\"\n",
    "        Find the classification threshold that minimizes the False Negative Rate (FNR)\n",
    "        and store it in self.prediction_threshold.\n",
    "    \n",
    "        Returns:\n",
    "            best_thresh (float): Threshold with the lowest FNR\n",
    "            best_fnr (float): Lowest observed FNR\n",
    "            thresholds (np.ndarray): Array of tested thresholds\n",
    "            fnrs (List[float]): FNRs corresponding to each threshold\n",
    "        \"\"\"\n",
    "    \n",
    "        assert hasattr(self, \"test_probs\") and hasattr(self, \"test_targets\"), \\\n",
    "            \"test_probs and test_targets must be defined (run test first).\"\n",
    "    \n",
    "        probs = torch.cat(self.test_probs).cpu().numpy()\n",
    "        targets = torch.cat(self.test_targets).cpu().numpy()\n",
    "    \n",
    "        thresholds = np.linspace(0, 1, 100)\n",
    "        best_thresh = 0.5\n",
    "        best_fnr = 1.0\n",
    "        fnrs = []\n",
    "    \n",
    "        for t in tqdm(thresholds):\n",
    "            preds = (probs >= t).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(targets, preds).ravel()\n",
    "            fnr = fn / (fn + tp) if (fn + tp) > 0 else 1.0\n",
    "            fnrs.append(fnr)\n",
    "    \n",
    "            if fnr < best_fnr:\n",
    "                best_fnr = fnr\n",
    "                best_thresh = t\n",
    "    \n",
    "        self.prediction_threshold = best_thresh\n",
    "    \n",
    "        return best_thresh, best_fnr, thresholds, fnrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25169b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    return [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=True, mode='min'),\n",
    "        LearningRateMonitor(logging_interval='epoch'),\n",
    "        ModelCheckpoint(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            verbose=True,\n",
    "            filename=f'{model_name}-best-checkpoint',\n",
    "            dirpath=os.path.join(\"lightning_logs\", model_name, \"checkpoints\")\n",
    "        )\n",
    "    ]\n",
    "def train_model(ModelClass, model_name, datamodule, input_size, k_folds=None, n_layers=5, h_size=64, return_model=False):\n",
    "    if k_folds:\n",
    "        print(f\"Training {model_name} with {k_folds}-fold cross-validation...\\n\")\n",
    "        trained_models = []\n",
    "\n",
    "        for fold in range(k_folds):\n",
    "            print(f\"\\n=== Fold {fold+1}/{k_folds} ===\")\n",
    "\n",
    "            # Re-initialize datamodule with current fold\n",
    "            fold_dm = TimeSeriesDataModule(\n",
    "                feature_cols=datamodule.feature_cols,\n",
    "                batch_size=datamodule.batch_size,\n",
    "                k_folds=k_folds,\n",
    "                fold_index=fold\n",
    "            )\n",
    "            fold_dm.setup()\n",
    "\n",
    "            model = ModelClass(input_size=input_size, hidden_size=h_size, num_layers=n_layers)\n",
    "            fold_name = f\"{model_name}-fold{fold}\"\n",
    "\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=20,\n",
    "                callbacks=get_callbacks(fold_name),\n",
    "                log_every_n_steps=10,\n",
    "                accelerator=\"auto\",\n",
    "                devices=\"auto\",\n",
    "                default_root_dir=os.path.join(\"lightning_logs\", fold_name)\n",
    "            )\n",
    "\n",
    "            trainer.fit(model, datamodule=fold_dm)\n",
    "\n",
    "            if return_model:\n",
    "                trained_models.append(model)\n",
    "\n",
    "            # Optional test after each fold\n",
    "            test_model(ModelClass, fold_name, fold_dm, model=model)\n",
    "\n",
    "        if return_model:\n",
    "            return trained_models\n",
    "\n",
    "    else:\n",
    "        print(f\"Training {model_name} without cross-validation...\")\n",
    "        model = ModelClass(input_size=input_size, hidden_size=h_size, num_layers=n_layers)\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=20,\n",
    "            callbacks=get_callbacks(model_name),\n",
    "            log_every_n_steps=10,\n",
    "            accelerator=\"auto\",\n",
    "            devices=\"auto\",\n",
    "            default_root_dir=os.path.join(\"lightning_logs\", model_name)\n",
    "        )\n",
    "\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "        if return_model:\n",
    "            return model\n",
    "\n",
    "\n",
    "def test_model(ModelClass, model_name, datamodule, model=None):\n",
    "    print(f\"Testing {model_name}...\")\n",
    "\n",
    "    if model is None:\n",
    "        # Load best checkpoint if model is not provided\n",
    "        ckpt_dir = os.path.join(\"lightning_logs\", model_name, \"checkpoints\")\n",
    "        ckpt_files = glob(os.path.join(ckpt_dir, \"*.ckpt\"))\n",
    "        best_ckpt_path = ckpt_files[0] if ckpt_files else None\n",
    "        print(f\"Checkpoint files found: {ckpt_files}\")\n",
    "\n",
    "        if best_ckpt_path:\n",
    "            print(f\"Best checkpoint: {best_ckpt_path}\")\n",
    "            model = ModelClass.load_from_checkpoint(best_ckpt_path)\n",
    "        else:\n",
    "            print(f\"No checkpoint found for model '{model_name}'. Skipping test.\")\n",
    "            return\n",
    "\n",
    "    trainer = pl.Trainer(accelerator=\"auto\", devices=\"auto\")\n",
    "    trainer.test(model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140bf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_and_train_and_eval_probe(datamodule, encoder_model):\n",
    "    X_train_embed, y_train = extract_embeddings(encoder_model, datamodule.train_dataloader())\n",
    "    X_test_embed, y_test = extract_embeddings(encoder_model, datamodule.test_dataloader())\n",
    "\n",
    "\n",
    "\n",
    "    df_embeddings = pd.DataFrame(X_train_embed)\n",
    "    df_embeddings[\"label\"] = y_train\n",
    "    df_embeddings.to_csv(\"patient_embeddings_train.csv\", index=False)\n",
    "    print(\"Embeddings saved to patient_embeddings_train.csv\")\n",
    "\n",
    "\n",
    "    df_embeddings = pd.DataFrame(X_test_embed)\n",
    "    df_embeddings[\"label\"] = y_test\n",
    "    df_embeddings.to_csv(\"patient_embeddings_test.csv\", index=False)\n",
    "    print(\"Embeddings saved to patient_embeddings_test.csv\")\n",
    "\n",
    "\n",
    "    train_and_eval_probe(X_train_embed, y_train, X_test_embed, y_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8592a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_label_scarcity_experiment(datamodule, encoder_model, input_size,):\n",
    "    sizes = [100, 500, 1000, 3999]\n",
    "\n",
    "    X_train_embed, y_train = extract_embeddings(encoder_model, datamodule.train_dataloader())\n",
    "    X_test_embed, y_test = extract_embeddings(encoder_model, datamodule.test_dataloader())\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    collector = ResultCollector()\n",
    "\n",
    "    for size in sizes:\n",
    "        print(f\"\\nTraining size: {size}\")\n",
    "        idx = np.random.choice(len(X_train_embed), size, replace=False)\n",
    "\n",
    "        # --- Linear Probe ---\n",
    "        X_train_small = X_train_embed[idx]\n",
    "        y_train_small = y_train[idx]\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        clf.fit(X_train_small, y_train_small)\n",
    "        probs_lp = clf.predict_proba(X_test_embed)[:, 1]\n",
    "        auroc_lp = roc_auc_score(y_test, probs_lp)\n",
    "        auprc_lp = average_precision_score(y_test, probs_lp)\n",
    "        print(f\"Linear Probe:\\n AuROC: {auroc_lp:.4f},\\n AuPRC: {auprc_lp:.4f}\")\n",
    "        collector.add(\"Linear Probe\", size, auroc_lp, auprc_lp)\n",
    "\n",
    "        # --- LSTM Classifier ---\n",
    "        lstm_model = train_model(LSTMClassifier, \"lstm\", datamodule, input_size, k_folds=k_folds, h_size = h_size, n_layers = n_layers, return_model=True)\n",
    "\n",
    "        test_loader = datamodule.test_dataloader()\n",
    "        probs = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                logits = lstm_model(x)\n",
    "                probs.append(torch.sigmoid(logits))\n",
    "                labels.append(y)\n",
    "        y_pred = torch.cat(probs).numpy()\n",
    "        y_true = torch.cat(labels).numpy()\n",
    "        auroc = roc_auc_score(y_true, y_pred)\n",
    "        auprc = average_precision_score(y_true, y_pred)\n",
    "        print(f\"LSTM:\\n AuROC: {auroc:.4f},\\n AuPRC: {auprc:.4f}\")\n",
    "        collector.add(\"LSTM\", size, auroc, auprc)\n",
    "\n",
    "    display(collector.to_df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8223b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class ResultCollector:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "\n",
    "    def add(self, model_type, train_size, auroc, auprc):\n",
    "        self.results.append({\n",
    "            \"Model\": model_type,\n",
    "            \"Train Size\": train_size,\n",
    "            \"AuROC\": auroc,\n",
    "            \"AuPRC\": auprc\n",
    "        })\n",
    "\n",
    "    def to_df(self):\n",
    "        return pd.DataFrame(self.results).sort_values([\"Train Size\", \"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c892cd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to patient_embeddings_train.csv\n",
      "Embeddings saved to patient_embeddings_test.csv\n",
      "Linear Probe:\n",
      " AuROC: 0.8265,\n",
      " AuPRC: 0.4662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training size: 100\n",
      "Linear Probe:\n",
      " AuROC: 0.7533,\n",
      " AuPRC: 0.3702\n",
      "Training lstm without cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | lstm       | LSTM              | 27.4 K | train\n",
      "1 | classifier | Linear            | 65     | train\n",
      "2 | loss_fn    | BCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "27.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 K    Total params\n",
      "0.110     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13739d69f15b40809df264d85d31ab77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.334\n",
      "Epoch 0, global step 63: 'val_loss' reached 0.33401 (best 0.33401), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v43.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.308\n",
      "Epoch 1, global step 126: 'val_loss' reached 0.30821 (best 0.30821), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v43.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.303\n",
      "Epoch 2, global step 189: 'val_loss' reached 0.30272 (best 0.30272), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v43.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 252: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 315: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 378: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 504: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 567: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 630: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 693: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.303. Signaling Trainer to stop.\n",
      "Epoch 12, global step 819: 'val_loss' was not in top 1\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      " AuROC: 0.8188,\n",
      " AuPRC: 0.4721\n",
      "\n",
      "Training size: 500\n",
      "Linear Probe:\n",
      " AuROC: 0.7737,\n",
      " AuPRC: 0.3869\n",
      "Training lstm without cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | lstm       | LSTM              | 27.4 K | train\n",
      "1 | classifier | Linear            | 65     | train\n",
      "2 | loss_fn    | BCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "27.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 K    Total params\n",
      "0.110     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ab0d4961e242ddb43d59133223cc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.324\n",
      "Epoch 0, global step 63: 'val_loss' reached 0.32443 (best 0.32443), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v44.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.313\n",
      "Epoch 1, global step 126: 'val_loss' reached 0.31339 (best 0.31339), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v44.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.301\n",
      "Epoch 2, global step 189: 'val_loss' reached 0.30096 (best 0.30096), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v44.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.301\n",
      "Epoch 3, global step 252: 'val_loss' reached 0.30061 (best 0.30061), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v44.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 315: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 378: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 504: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 567: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 630: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 693: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 819: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.301. Signaling Trainer to stop.\n",
      "Epoch 13, global step 882: 'val_loss' was not in top 1\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      " AuROC: 0.8110,\n",
      " AuPRC: 0.4648\n",
      "\n",
      "Training size: 1000\n",
      "Linear Probe:\n",
      " AuROC: 0.8071,\n",
      " AuPRC: 0.4584\n",
      "Training lstm without cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | lstm       | LSTM              | 27.4 K | train\n",
      "1 | classifier | Linear            | 65     | train\n",
      "2 | loss_fn    | BCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "27.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 K    Total params\n",
      "0.110     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db16c1162b54569b436d297532d1bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.328\n",
      "Epoch 0, global step 63: 'val_loss' reached 0.32808 (best 0.32808), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v45.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.308\n",
      "Epoch 1, global step 126: 'val_loss' reached 0.30795 (best 0.30795), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v45.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.302\n",
      "Epoch 2, global step 189: 'val_loss' reached 0.30188 (best 0.30188), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v45.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.301\n",
      "Epoch 3, global step 252: 'val_loss' reached 0.30053 (best 0.30053), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v45.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 315: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 378: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 504: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 567: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 630: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 693: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 819: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.301. Signaling Trainer to stop.\n",
      "Epoch 13, global step 882: 'val_loss' was not in top 1\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      " AuROC: 0.7999,\n",
      " AuPRC: 0.4463\n",
      "\n",
      "Training size: 3999\n",
      "Linear Probe:\n",
      " AuROC: 0.8265,\n",
      " AuPRC: 0.4661\n",
      "Training lstm without cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | lstm       | LSTM              | 27.4 K | train\n",
      "1 | classifier | Linear            | 65     | train\n",
      "2 | loss_fn    | BCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "27.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 K    Total params\n",
      "0.110     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1097f9066aaf4a7fba05a98ec1a5c320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.335\n",
      "Epoch 0, global step 63: 'val_loss' reached 0.33543 (best 0.33543), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v46.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.316\n",
      "Epoch 1, global step 126: 'val_loss' reached 0.31618 (best 0.31618), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v46.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.307\n",
      "Epoch 2, global step 189: 'val_loss' reached 0.30667 (best 0.30667), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v46.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.307\n",
      "Epoch 3, global step 252: 'val_loss' reached 0.30665 (best 0.30665), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v46.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.304\n",
      "Epoch 4, global step 315: 'val_loss' reached 0.30392 (best 0.30392), saving model to '/Users/damlaortac/Desktop/ML for HC/Project 1/ICU-TimeSeries-Mortality-Prediction/data/lightning_logs/lstm/checkpoints/lstm-best-checkpoint-v46.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 378: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 504: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 567: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 630: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 693: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 819: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 882: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.304. Signaling Trainer to stop.\n",
      "Epoch 14, global step 945: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      " AuROC: 0.8000,\n",
      " AuPRC: 0.4399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>AuROC</th>\n",
       "      <th>AuPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>0.818771</td>\n",
       "      <td>0.472098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Probe</td>\n",
       "      <td>100</td>\n",
       "      <td>0.753322</td>\n",
       "      <td>0.370153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>500</td>\n",
       "      <td>0.811018</td>\n",
       "      <td>0.464785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Probe</td>\n",
       "      <td>500</td>\n",
       "      <td>0.773654</td>\n",
       "      <td>0.386910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.799932</td>\n",
       "      <td>0.446320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Probe</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.807144</td>\n",
       "      <td>0.458378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>3999</td>\n",
       "      <td>0.800019</td>\n",
       "      <td>0.439871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Probe</td>\n",
       "      <td>3999</td>\n",
       "      <td>0.826494</td>\n",
       "      <td>0.466060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Train Size     AuROC     AuPRC\n",
       "1          LSTM         100  0.818771  0.472098\n",
       "0  Linear Probe         100  0.753322  0.370153\n",
       "3          LSTM         500  0.811018  0.464785\n",
       "2  Linear Probe         500  0.773654  0.386910\n",
       "5          LSTM        1000  0.799932  0.446320\n",
       "4  Linear Probe        1000  0.807144  0.458378\n",
       "7          LSTM        3999  0.800019  0.439871\n",
       "6  Linear Probe        3999  0.826494  0.466060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ID_vars = [\"PatientID\", \"Time\", \"RecordID\"]\n",
    "stationary_vars = [\"Age\", \"Gender\", \"Height\"] #, \"ICUType\"]\n",
    "dynamic_vars = df_a.columns.difference(stationary_vars + ID_vars + [\"In-hospital_death\"]).tolist()\n",
    "feature_cols = dynamic_vars + stationary_vars\n",
    "\n",
    "# Setup\n",
    "k_folds = None\n",
    "h_size = 64\n",
    "n_layers = 1\n",
    "input_size = len(feature_cols) + 1\n",
    "datamodule = TimeSeriesDataModule(feature_cols=feature_cols, batch_size=64, k_folds = k_folds)\n",
    "\n",
    "datamodule.setup()\n",
    "\n",
    "autoencoder = LSTMAutoencoder(input_size=input_size)\n",
    "\n",
    "\n",
    "compute_embedding_and_train_and_eval_probe(datamodule, autoencoder)\n",
    "run_label_scarcity_experiment(datamodule, autoencoder, input_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f5aaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682032e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
